{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "02_fully_connected_practice.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOKjFNUxvucP",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEuB2VVMvyDD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "collapsed": true,
        "outputId": "74f486ee-591a-440d-f3a4-4105a4f745e4"
      },
      "source": [
        "!curl -s https://course.fast.ai/setup/colab | bash\n",
        "!git clone https://github.com/SpellOnYou/dlff-note.git\n",
        "import os\n",
        "os.chdir('/content/dlff-note/nbs/dl2/')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n",
            "Cloning into 'dlff-note'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 5258 (delta 4), reused 11 (delta 4), pack-reused 5245\u001b[K\n",
            "Receiving objects: 100% (5258/5258), 239.06 MiB | 32.84 MiB/s, done.\n",
            "Resolving deltas: 100% (2847/2847), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npPSloDnvCB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra6Vn40uvCB-",
        "colab_type": "text"
      },
      "source": [
        "## The forward and backward passes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OwCvEwZvCB_",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=4960)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3Bm-cWbvCCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from exp.nb_01 import *\n",
        "\n",
        "def get_data():\n",
        "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
        "    with gzip.open(path, 'rb') as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
        "\n",
        "def normalize(x, m, s): return (x-m)/s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMtLADkpvCCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmdRLjLpvCCG",
        "colab_type": "code",
        "outputId": "2f49a5a4-db00-44c9-91a0-6a1dacddacca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_mean,train_std = x_train.mean(),x_train.std()\n",
        "train_mean,train_std"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1304), tensor(0.3073))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2URaFD1vCCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = normalize(x_train, train_mean, train_std)\n",
        "# NB: Use training, not validation mean for validation set\n",
        "x_valid = normalize(x_valid, train_mean, train_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_NnyM0bvCCK",
        "colab_type": "code",
        "outputId": "e697fea8-2fe3-41f1-ac71-f175e842d0d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_mean,train_std = x_train.mean(),x_train.std()\n",
        "train_mean,train_std"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0001), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXa9TNHGvCCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFzXjz_SvCCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near_zero(x_train.mean())\n",
        "test_near_zero(1-x_train.std())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACOF-g_PvCCQ",
        "colab_type": "code",
        "outputId": "028ae507-f22d-4ba3-b451-63e1caf13c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "n,m,c"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 784, tensor(10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxR0s0A3vCCR",
        "colab_type": "text"
      },
      "source": [
        "## Foundations version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52164hDpvCCS",
        "colab_type": "text"
      },
      "source": [
        "### Basic architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgdhyKbjvCCT",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=5128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CENsNGWEvCCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num hidden\n",
        "nh = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5wdmt8EvCCW",
        "colab_type": "text"
      },
      "source": [
        "[Thinker practice](https://course.fast.ai/videos/?lesson=8&t=5255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcN49beDaUOd",
        "colab_type": "text"
      },
      "source": [
        "##### Just grap some normal random numbers with linear function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGRS0ORPbj3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lin(x, w, b): return x@w + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCoqkyysY3_t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "732c31e6-a12b-4e3c-c78a-aa230395c18d"
      },
      "source": [
        "# If we do not divide by sqrt\n",
        "w1 = torch.randn(m,nh)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh,1)\n",
        "b2 = torch.zeros(1)\n",
        "t = lin(x_valid, w1, b1) # hidden\n",
        "t.mean(), t.std()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1.0229), tensor(29.5775))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waSc4Thiasdv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d447e70-11e4-479f-91b7-250b441f4d42"
      },
      "source": [
        "t2 = lin(t, w2, b2) # output\n",
        "t2.mean(), t2.std()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0824), tensor(0.7760))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvBOdSPxbvD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7caa2c0-6e0b-4a00-8bb6-0a92e8678d25"
      },
      "source": [
        "t.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AhJMFTwbsO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "144c119a-a26b-46a0-e3fa-d28a441074fe"
      },
      "source": [
        "t2.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olrw9Jq9ZxFd",
        "colab_type": "text"
      },
      "source": [
        "##### Divide sqrt to make std 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh5uru6FvCCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# simplified kaiming init / he init\n",
        "w1 = torch.randn(m,nh)/math.sqrt(m)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh,1)/math.sqrt(nh)\n",
        "b2 = torch.zeros(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoVgkMUkvCCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near_zero(w1.mean())\n",
        "test_near_zero(w1.std()-1/math.sqrt(m))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUNxBJkCvCCa",
        "colab_type": "code",
        "outputId": "68ddfe42-0fb8-4219-dd81-a4227dbb612d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# This should be ~ (0,1) (mean,std)...\n",
        "x_valid.mean(),x_valid.std()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0057), tensor(0.9924))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTKD22YbvCCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = lin(x_valid, w1, b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6aOp1__vCCi",
        "colab_type": "code",
        "outputId": "902667b6-8913-4b15-de5d-24ccc61271f3",
        "colab": {}
      },
      "source": [
        "#...so should this, because we used kaiming init, which is designed to do this\n",
        "t.mean(),t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2035), tensor(1.0095))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40LqH25tvCCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x): return x.clamp_min(0.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18kpYfq3vCCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = relu(lin(x_valid, w1, b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuX_TQPtvCCo",
        "colab_type": "code",
        "outputId": "c97d49a8-434b-4191-bce1-683570f6d390",
        "colab": {}
      },
      "source": [
        "#...actually it really should be this!\n",
        "t.mean(),t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5063), tensor(0.6765))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUg8yU3vvCCs",
        "colab_type": "text"
      },
      "source": [
        "From pytorch docs: `a: the negative slope of the rectifier used after this layer (0 for ReLU by default)`\n",
        "\n",
        "$$\\text{std} = \\sqrt{\\frac{2}{(1 + a^2) \\times \\text{fan_in}}}$$\n",
        "\n",
        "This was introduced in the paper that described the Imagenet-winning approach from *He et al*: [Delving Deep into Rectifiers](https://arxiv.org/abs/1502.01852), which was also the first paper that claimed \"super-human performance\" on Imagenet (and, most importantly, it introduced resnets!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46CazCTMvCCt",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=5128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxPyasPovCCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# kaiming init / he init for relu\n",
        "w1 = torch.randn(m,nh)*math.sqrt(2/m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNRRds6wvCCw",
        "colab_type": "code",
        "outputId": "c73cdd73-17ad-45c7-bd29-8ba92f4a4200",
        "colab": {}
      },
      "source": [
        "w1.mean(),w1.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0001), tensor(0.0508))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3jqhHejvCCy",
        "colab_type": "code",
        "outputId": "82671914-50ec-44d7-9748-fbf7ce8978f3",
        "colab": {}
      },
      "source": [
        "t = relu(lin(x_valid, w1, b1))\n",
        "t.mean(),t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5678), tensor(0.8491))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5jyoCjOvCC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch.nn import init"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nm7rFJyvCC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1 = torch.zeros(m,nh)\n",
        "init.kaiming_normal_(w1, mode='fan_out')\n",
        "t = relu(lin(x_valid, w1, b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIDJJHOvvCC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init.kaiming_normal_??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QIhalvlvCC7",
        "colab_type": "code",
        "outputId": "85be8d5b-b4c0-4fcc-d3b3-d1ed4955fd1f",
        "colab": {}
      },
      "source": [
        "w1.mean(),w1.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0001), tensor(0.0502))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HULMYxz5vCC-",
        "colab_type": "code",
        "outputId": "df4d058e-ba7e-44ca-c461-f4994acb07a9",
        "colab": {}
      },
      "source": [
        "t.mean(),t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5542), tensor(0.8006))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwXQGif_vCDA",
        "colab_type": "code",
        "outputId": "ee2e599f-bfaa-4b10-f1a3-66715afb00cf",
        "colab": {}
      },
      "source": [
        "w1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gft8wWdBvCDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quDCPThkvCDE",
        "colab_type": "code",
        "outputId": "3dacef22-2de3-47f6-908a-3cbaf3bbb4a8",
        "colab": {}
      },
      "source": [
        "torch.nn.Linear(m,nh).weight.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47oNSHiFvCDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.Linear.forward??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGI_xKnPvCDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.functional.linear??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm-8gSykvCDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.Conv2d??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5-azfxuvCDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.modules.conv._ConvNd.reset_parameters??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8mOdusevCDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# what if...?\n",
        "def relu(x): return x.clamp_min(0.) - 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0229qDAuvCDS",
        "colab_type": "code",
        "outputId": "8692311c-8aa1-43ea-e98a-eec0504e1f76",
        "colab": {}
      },
      "source": [
        "# kaiming init / he init for relu\n",
        "w1 = torch.randn(m,nh)*math.sqrt(2./m )\n",
        "t1 = relu(lin(x_valid, w1, b1))\n",
        "t1.mean(),t1.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1071), tensor(0.8995))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywk-diQ0vCDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(xb):\n",
        "    l1 = lin(xb, w1, b1)\n",
        "    l2 = relu(l1)\n",
        "    l3 = lin(l2, w2, b2)\n",
        "    return l3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bofx3go8vCDV",
        "colab_type": "code",
        "outputId": "966ff8e2-60fe-46f5-8764-9fc14276d140",
        "colab": {}
      },
      "source": [
        "%timeit -n 10 _=model(x_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8.41 ms ± 1.07 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbFwKib3vCDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert model(x_valid).shape==torch.Size([x_valid.shape[0],1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCpWx1KXvCDX",
        "colab_type": "text"
      },
      "source": [
        "### Loss function: MSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvjkqMOuvCDY",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=6372)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9jScx7ivCDY",
        "colab_type": "code",
        "outputId": "e2598a3d-2689-494f-d50d-c803bcdebead",
        "colab": {}
      },
      "source": [
        "model(x_valid).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa7Yt6vzvCDa",
        "colab_type": "text"
      },
      "source": [
        "We need `squeeze()` to get rid of that trailing (,1), in order to use `mse`. (Of course, `mse` is not a suitable loss function for multi-class classification; we'll use a better loss function soon. We'll use `mse` for now to keep things simple.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5Mb9mXevCDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0_D80revCDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train,y_valid = y_train.float(),y_valid.float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6P96B7mvCDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4vJFDfJvCDh",
        "colab_type": "code",
        "outputId": "5cc3e30f-b064-4053-cb80-322a990e987e",
        "colab": {}
      },
      "source": [
        "preds.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_84xNN3AvCDi",
        "colab_type": "code",
        "outputId": "0ff740af-0f83-4bc2-f6a1-fe6c3f6df06d",
        "colab": {}
      },
      "source": [
        "mse(preds, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(33.4708)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7Jdf_NjvCDl",
        "colab_type": "text"
      },
      "source": [
        "### Gradients and backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYOLsnJyvCDl",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=6493)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_-y_OmnvCDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse_grad(inp, targ): \n",
        "    # grad of loss with respect to output of previous layer\n",
        "    inp.g = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBDu7j_qvCDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu_grad(inp, out):\n",
        "    # grad of relu with respect to input activations\n",
        "    inp.g = (inp>0).float() * out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZcrYljxvCDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lin_grad(inp, out, w, b):\n",
        "    # grad of matmul with respect to input\n",
        "    inp.g = out.g @ w.t()\n",
        "    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
        "    b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWnG8TSSvCDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_and_backward(inp, targ):\n",
        "    # forward pass:\n",
        "    l1 = inp @ w1 + b1\n",
        "    l2 = relu(l1)\n",
        "    out = l2 @ w2 + b2\n",
        "    # we don't actually need the loss in backward!\n",
        "    loss = mse(out, targ)\n",
        "    \n",
        "    # backward pass:\n",
        "    mse_grad(out, targ)\n",
        "    lin_grad(l2, out, w2, b2)\n",
        "    relu_grad(l1, l2)\n",
        "    lin_grad(inp, l1, w1, b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8lfySw-vCDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forward_and_backward(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDjwnZJAvCDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save for testing against later\n",
        "w1g = w1.g.clone()\n",
        "w2g = w2.g.clone()\n",
        "b1g = b1.g.clone()\n",
        "b2g = b2.g.clone()\n",
        "ig  = x_train.g.clone()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AkGyVgovCDx",
        "colab_type": "text"
      },
      "source": [
        "We cheat a little bit and use PyTorch autograd to check our results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2sBYxSyvCDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xt2 = x_train.clone().requires_grad_(True)\n",
        "w12 = w1.clone().requires_grad_(True)\n",
        "w22 = w2.clone().requires_grad_(True)\n",
        "b12 = b1.clone().requires_grad_(True)\n",
        "b22 = b2.clone().requires_grad_(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXRezmXavCDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(inp, targ):\n",
        "    # forward pass:\n",
        "    l1 = inp @ w12 + b12\n",
        "    l2 = relu(l1)\n",
        "    out = l2 @ w22 + b22\n",
        "    # we don't actually need the loss in backward!\n",
        "    return mse(out, targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxtbRtSLvCD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = forward(xt2, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQao3tw4vCD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbfSqSz1vCD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w22.grad, w2g)\n",
        "test_near(b22.grad, b2g)\n",
        "test_near(w12.grad, w1g)\n",
        "test_near(b12.grad, b1g)\n",
        "test_near(xt2.grad, ig )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HNIwHNGvCD7",
        "colab_type": "text"
      },
      "source": [
        "## Refactor model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIrWDGruvCD8",
        "colab_type": "text"
      },
      "source": [
        "### Layers as classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXdcU1i1vCD_",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=7112)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bjA9l64vCEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu():\n",
        "    def __call__(self, inp):\n",
        "        self.inp = inp\n",
        "        self.out = inp.clamp_min(0.)-0.5\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self): self.inp.g = (self.inp>0).float() * self.out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSY7DCE6vCEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin():\n",
        "    def __init__(self, w, b): self.w,self.b = w,b\n",
        "        \n",
        "    def __call__(self, inp):\n",
        "        self.inp = inp\n",
        "        self.out = inp@self.w + self.b\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        self.inp.g = self.out.g @ self.w.t()\n",
        "        # Creating a giant outer product, just to sum it, is inefficient!\n",
        "        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
        "        self.b.g = self.out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwx7XeApvCEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mse():\n",
        "    def __call__(self, inp, targ):\n",
        "        self.inp = inp\n",
        "        self.targ = targ\n",
        "        self.out = (inp.squeeze() - targ).pow(2).mean()\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKd7lQnUvCEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "    def __init__(self, w1, b1, w2, b2):\n",
        "        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n",
        "        self.loss = Mse()\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x, targ)\n",
        "    \n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for l in reversed(self.layers): l.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRthL98vvCEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model(w1, b1, w2, b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4B_5Tl6vCEL",
        "colab_type": "code",
        "outputId": "77817163-4d20-4c08-fce1-137cf1bcc564",
        "colab": {}
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 137 ms, sys: 4.95 ms, total: 142 ms\n",
            "Wall time: 70.7 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36RqbnykvCEO",
        "colab_type": "code",
        "outputId": "d40e737d-61b5-4694-8295-c26366aafc52",
        "colab": {}
      },
      "source": [
        "%time model.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.84 s, sys: 3.86 s, total: 6.71 s\n",
            "Wall time: 3.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkuK7yYtvCER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w2g, w2.g)\n",
        "test_near(b2g, b2.g)\n",
        "test_near(w1g, w1.g)\n",
        "test_near(b1g, b1.g)\n",
        "test_near(ig, x_train.g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP26MpJIvCEU",
        "colab_type": "text"
      },
      "source": [
        "### Module.forward()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqEBjamPvCEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Module():\n",
        "    def __call__(self, *args):\n",
        "        self.args = args\n",
        "        self.out = self.forward(*args)\n",
        "        return self.out\n",
        "    \n",
        "    def forward(self): raise Exception('not implemented')\n",
        "    def backward(self): self.bwd(self.out, *self.args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baN7cq_1vCEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu(Module):\n",
        "    def forward(self, inp): return inp.clamp_min(0.)-0.5\n",
        "    def bwd(self, out, inp): inp.g = (inp>0).float() * out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzOg0G3TvCEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin(Module):\n",
        "    def __init__(self, w, b): self.w,self.b = w,b\n",
        "        \n",
        "    def forward(self, inp): return inp@self.w + self.b\n",
        "    \n",
        "    def bwd(self, out, inp):\n",
        "        inp.g = out.g @ self.w.t()\n",
        "        self.w.g = torch.einsum(\"bi,bj->ij\", inp, out.g)\n",
        "        self.b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuvD4ILgvCEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mse(Module):\n",
        "    def forward (self, inp, targ): return (inp.squeeze() - targ).pow(2).mean()\n",
        "    def bwd(self, out, inp, targ): inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn0pSLRYvCEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "    def __init__(self):\n",
        "        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n",
        "        self.loss = Mse()\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x, targ)\n",
        "    \n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for l in reversed(self.layers): l.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kzTL0GtvCEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDt-Nnv3vCEf",
        "colab_type": "code",
        "outputId": "d4a63df8-d219-4274-a2d0-1f3e6f9d35c8",
        "colab": {}
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 86 ms, sys: 8.25 ms, total: 94.2 ms\n",
            "Wall time: 46.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14_dh0u5vCEg",
        "colab_type": "code",
        "outputId": "8b9c3569-9057-4056-d7fa-93be0446a79c",
        "colab": {}
      },
      "source": [
        "%time model.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 193 ms, sys: 87.6 ms, total: 280 ms\n",
            "Wall time: 140 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEMvPHTkvCEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w2g, w2.g)\n",
        "test_near(b2g, b2.g)\n",
        "test_near(w1g, w1.g)\n",
        "test_near(b1g, b1.g)\n",
        "test_near(ig, x_train.g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bngO0c4EvCEj",
        "colab_type": "text"
      },
      "source": [
        "### Without einsum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5iQVSasvCEj",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=7484)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUWJCOWzvCEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin(Module):\n",
        "    def __init__(self, w, b): self.w,self.b = w,b\n",
        "        \n",
        "    def forward(self, inp): return inp@self.w + self.b\n",
        "    \n",
        "    def bwd(self, out, inp):\n",
        "        inp.g = out.g @ self.w.t()\n",
        "        self.w.g = inp.t() @ out.g\n",
        "        self.b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvv_vkCevCEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H-pX00hvCEm",
        "colab_type": "code",
        "outputId": "b2dee9b5-3956-445c-dc8d-0a41e38b5a99",
        "colab": {}
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 88.6 ms, sys: 5.04 ms, total: 93.6 ms\n",
            "Wall time: 46.4 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhDRbmqnvCEn",
        "colab_type": "code",
        "outputId": "9e0f8942-0e1c-4e3c-bdf4-9edf6d910a0b",
        "colab": {}
      },
      "source": [
        "%time model.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 197 ms, sys: 83.9 ms, total: 281 ms\n",
            "Wall time: 140 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWKmQAWOvCEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w2g, w2.g)\n",
        "test_near(b2g, b2.g)\n",
        "test_near(w1g, w1.g)\n",
        "test_near(b1g, b1.g)\n",
        "test_near(ig, x_train.g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhGSp5lSvCEs",
        "colab_type": "text"
      },
      "source": [
        "### nn.Linear and nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHKCU19ovCEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0w_NYEJvCEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "        self.loss = mse\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x.squeeze(), targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJTK3khQvCEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCDqkYE_vCEv",
        "colab_type": "code",
        "outputId": "ad00f500-54f7-4438-c422-85f14d7c50d0",
        "colab": {}
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 85.1 ms, sys: 8.16 ms, total: 93.3 ms\n",
            "Wall time: 46.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuC4z-Y4vCEw",
        "colab_type": "code",
        "outputId": "99c7a7f8-3e57-4ac2-a049-48e404d86e1e",
        "colab": {}
      },
      "source": [
        "%time loss.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 135 ms, sys: 78.1 ms, total: 213 ms\n",
            "Wall time: 71.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov7pCiYmvCEx",
        "colab_type": "text"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FDM9rE4vCEy",
        "colab_type": "code",
        "outputId": "8ff21a5c-5b74-4dd7-e4c5-b8ee74a02563",
        "colab": {}
      },
      "source": [
        "!./notebook2script.py 02_fully_connected.ipynb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 02_fully_connected.ipynb to nb_02.py\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYee07MJvCEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}