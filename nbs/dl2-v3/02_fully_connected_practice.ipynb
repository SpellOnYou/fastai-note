{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "02_fully_connected_practice.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QOKjFNUxvucP",
        "ra6Vn40uvCB-",
        "52164hDpvCCS",
        "xCpWx1KXvCDX",
        "jkLyRrrCrHQO"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOKjFNUxvucP",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYbMVvBjC-TN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "b4c61000-c426-4c78-9249-16514796c574"
      },
      "source": [
        "# check GPU\n",
        "!pip install gpustat\n",
        "!gpustat -i 1"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpustat in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.6/dist-packages (from gpustat) (1.7)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from gpustat) (1.12.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from gpustat) (5.4.8)\n",
            "\u001b7\u001b[?47h\u001b7\u001b[1;1H\u001b[1m\u001b[37m4c5852b68148           \u001b[m  Fri Dec 13 20:31:10 2019  \u001b[1m\u001b[30m418.67\u001b[m\u001b[K\n",
            "\u001b[36m[0]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 43'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m16280\u001b[m MB |\u001b[K\n",
            "\u001b[J\u001b8\u001b7\u001b[1;1H\u001b[1m\u001b[37m4c5852b68148           \u001b[m  Fri Dec 13 20:31:11 2019  \u001b[1m\u001b[30m418.67\u001b[m\u001b[K\n",
            "\u001b[36m[0]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 43'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m16280\u001b[m MB |\u001b[K\n",
            "\u001b[J\u001b8\u001b7\u001b[1;1H\u001b[1m\u001b[37m4c5852b68148           \u001b[m  Fri Dec 13 20:31:12 2019  \u001b[1m\u001b[30m418.67\u001b[m\u001b[K\n",
            "\u001b[36m[0]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 43'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m16280\u001b[m MB |\u001b[K\n",
            "\u001b[J\u001b8\u001b7\u001b[1;1H\u001b[1m\u001b[37m4c5852b68148           \u001b[m  Fri Dec 13 20:31:13 2019  \u001b[1m\u001b[30m418.67\u001b[m\u001b[K\n",
            "\u001b[36m[0]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 43'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m16280\u001b[m MB |\u001b[K\n",
            "\u001b[J\u001b8\u001b7\u001b[1;1H\u001b[1m\u001b[37m4c5852b68148           \u001b[m  Fri Dec 13 20:31:14 2019  \u001b[1m\u001b[30m418.67\u001b[m\u001b[K\n",
            "\u001b[36m[0]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 43'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m16280\u001b[m MB |\u001b[K\n",
            "\u001b[J\u001b8\u001b7\u001b[1;1H\u001b[1m\u001b[37m4c5852b68148           \u001b[m  Fri Dec 13 20:31:15 2019  \u001b[1m\u001b[30m418.67\u001b[m\u001b[K\n",
            "\u001b[36m[0]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 43'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m16280\u001b[m MB |\u001b[K\n",
            "\u001b[J\u001b8\u001b[2J\u001b[?47l\u001b8"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQCfoTEaG7Jq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "\n",
        "# pretty print all cell's output and not just the last one\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEuB2VVMvyDD",
        "colab_type": "code",
        "collapsed": true,
        "outputId": "dedcd4b8-f1cb-411a-93a2-1a1710874062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "!curl -s https://course.fast.ai/setup/colab | bash\n",
        "!git clone https://github.com/SpellOnYou/dlff-note.git\n",
        "import os\n",
        "os.chdir('/content/dlff-note/nbs/dl2/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n",
            "Cloning into 'dlff-note'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 5332 (delta 20), reused 37 (delta 16), pack-reused 5282\u001b[K\n",
            "Receiving objects: 100% (5332/5332), 240.20 MiB | 50.74 MiB/s, done.\n",
            "Resolving deltas: 100% (2881/2881), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NANPUQQvWxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%script false\n",
        "pip freeze"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npPSloDnvCB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra6Vn40uvCB-",
        "colab_type": "text"
      },
      "source": [
        "## The forward and backward passes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OwCvEwZvCB_",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=4960)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3Bm-cWbvCCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from exp.nb_01 import *\n",
        "\n",
        "def get_data():\n",
        "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
        "    with gzip.open(path, 'rb') as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
        "\n",
        "def normalize(x, m, s): return (x-m)/s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMtLADkpvCCD",
        "colab_type": "code",
        "outputId": "b178877f-11ff-4d96-8439-cf404402a03d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://deeplearning.net/data/mnist/mnist.pkl\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmdRLjLpvCCG",
        "colab_type": "code",
        "outputId": "2c59e2ea-4053-430d-b5f0-ee45c2ae5001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#getting mean and std\n",
        "train_mean,train_std = x_train.mean(),x_train.std()\n",
        "train_mean,train_std"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1304), tensor(0.3073))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2URaFD1vCCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# apply it to train and valid\n",
        "x_train = normalize(x_train, train_mean, train_std)\n",
        "# NB: Use training, not validation mean for validation set\n",
        "x_valid = normalize(x_valid, train_mean, train_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_NnyM0bvCCK",
        "colab_type": "code",
        "outputId": "f90eeba1-332f-404d-d306-f496ac93ee76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_mean,train_std = x_train.mean(),x_train.std()\n",
        "train_mean,train_std"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3.0614e-05), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXa9TNHGvCCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFzXjz_SvCCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near_zero(x_train.mean())\n",
        "test_near_zero(1-x_train.std())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACOF-g_PvCCQ",
        "colab_type": "code",
        "outputId": "fe4c269e-7434-478d-cc2b-336f00cfecdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "n,m,c"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 784, tensor(10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxR0s0A3vCCR",
        "colab_type": "text"
      },
      "source": [
        "## Foundations version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52164hDpvCCS",
        "colab_type": "text"
      },
      "source": [
        "### Basic architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkjpFa3GBUGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nh = 50\n",
        "def lin(x, w, b): return x@w + b;\n",
        "w1 = torch.randn(m,nh)*math.sqrt(2./m ); b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh,1); b2 = torch.zeros(1)\n",
        "\n",
        "def relu(x): return x.clamp_min(0.) - 0.5\n",
        "t1 = relu(lin(x_valid, w1, b1))\n",
        "\n",
        "def model(xb):\n",
        "    l1 = lin(xb, w1, b1) # one linear layer\n",
        "    l2 = relu(l1) # one relu layer\n",
        "    l3 = lin(l2, w2, b2) # one more linear layer\n",
        "    return l3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgdhyKbjvCCT",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=5128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CENsNGWEvCCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num hidden\n",
        "nh = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5wdmt8EvCCW",
        "colab_type": "text"
      },
      "source": [
        "[Thinker practice](https://course.fast.ai/videos/?lesson=8&t=5255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcN49beDaUOd",
        "colab_type": "text"
      },
      "source": [
        "##### Just grap some normal random numbers with linear function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGRS0ORPbj3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lin(x, w, b): return x@w + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCoqkyysY3_t",
        "colab_type": "code",
        "outputId": "74140f0c-47ef-43b6-a09a-11acf8044c38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# If we do not divide by sqrt\n",
        "w1 = torch.randn(m,nh)\n",
        "b1 = torch.zeros(nh)\n",
        "t = lin(x_valid, w1, b1) # hidden\n",
        "t.mean(), t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2.4355), tensor(28.4015))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waSc4Thiasdv",
        "colab_type": "code",
        "outputId": "aa03e112-4ac4-41d4-ef4e-175f1fe7ab09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "w2 = torch.randn(nh,1)\n",
        "b2 = torch.zeros(1)\n",
        "t2 = lin(t, w2, b2) # output\n",
        "t2.mean(), t2.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(22.4911), tensor(198.5335))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvBOdSPxbvD1",
        "colab_type": "code",
        "outputId": "06479991-782d-47ab-d002-211e9e11b614",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t.shape, t2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10000, 50]), torch.Size([10000, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olrw9Jq9ZxFd",
        "colab_type": "text"
      },
      "source": [
        "##### Kaiming Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh5uru6FvCCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# simplified kaiming init / he init\n",
        "w1 = torch.randn(m,nh)/math.sqrt(m)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh,1)/math.sqrt(nh)\n",
        "b2 = torch.zeros(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoVgkMUkvCCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near_zero(w1.mean())\n",
        "test_near_zero(w1.std()-1/math.sqrt(m))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUNxBJkCvCCa",
        "colab_type": "code",
        "outputId": "b736d19f-2a1c-4c5c-c27a-fb6537380c3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# This should be ~ (0,1) (mean,std)...\n",
        "x_valid.mean(),x_valid.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0057), tensor(0.9924))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTKD22YbvCCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = lin(x_valid, w1, b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6aOp1__vCCi",
        "colab_type": "code",
        "outputId": "db1ad0e5-7ecf-4ae1-d305-ef0c8125f773",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#...so should this, because we used kaiming init, which is designed to do this\n",
        "t.mean(),t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1555), tensor(1.0225))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40LqH25tvCCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x): return x.clamp_min(0.) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18kpYfq3vCCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = relu(lin(x_valid, w1, b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuX_TQPtvCCo",
        "colab_type": "code",
        "outputId": "af3ef270-fd0b-4c80-b1c5-eb0ea22f1427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#...actually it really should be this!\n",
        "t.mean(),t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4855), tensor(0.6525))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUg8yU3vvCCs",
        "colab_type": "text"
      },
      "source": [
        "From pytorch docs: `a: the negative slope of the rectifier used after this layer (0 for ReLU by default)`\n",
        "\n",
        "$$\\text{std} = \\sqrt{\\frac{2}{(1 + a^2) \\times \\text{fan_in}}}$$\n",
        "\n",
        "This was introduced in the paper that described the Imagenet-winning approach from *He et al*: [Delving Deep into Rectifiers](https://arxiv.org/abs/1502.01852), which was also the first paper that claimed \"super-human performance\" on Imagenet (and, most importantly, it introduced resnets!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46CazCTMvCCt",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=5128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxPyasPovCCu",
        "colab_type": "code",
        "outputId": "91c3127c-1660-45e6-b62a-7f285d39a8f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# kaiming init / he init for relu\n",
        "w1 = torch.randn(m,nh)*math.sqrt(2/m)\n",
        "w1.mean(),w1.std()\n",
        "\n",
        "t = relu(lin(x_valid, w1, b1))\n",
        "t.mean(),t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4889), tensor(0.7556))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aiz3JXo__bew",
        "colab_type": "text"
      },
      "source": [
        "##### Torch package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5jyoCjOvCC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch.nn import init"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nm7rFJyvCC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1 = torch.zeros(m,nh)\n",
        "init.kaiming_normal_(w1, mode='fan_out') # why fan_out??\n",
        "t = relu(lin(x_valid, w1, b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIDJJHOvvCC6",
        "colab_type": "code",
        "outputId": "73eaebc3-87db-4131-eb01-eb866b976e61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# init.kaiming_normal_??\n",
        "help(init.kaiming_normal_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function kaiming_normal_ in module torch.nn.init:\n",
            "\n",
            "kaiming_normal_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
            "    Fills the input `Tensor` with values according to the method\n",
            "    described in `Delving deep into rectifiers: Surpassing human-level\n",
            "    performance on ImageNet classification` - He, K. et al. (2015), using a\n",
            "    normal distribution. The resulting tensor will have values sampled from\n",
            "    :math:`\\mathcal{N}(0, \\text{std}^2)` where\n",
            "    \n",
            "    .. math::\n",
            "        \\text{std} = \\sqrt{\\frac{2}{(1 + a^2) \\times \\text{fan\\_in}}}\n",
            "    \n",
            "    Also known as He initialization.\n",
            "    \n",
            "    Args:\n",
            "        tensor: an n-dimensional `torch.Tensor`\n",
            "        a: the negative slope of the rectifier used after this layer (0 for ReLU\n",
            "            by default)\n",
            "        mode: either ``'fan_in'`` (default) or ``'fan_out'``. Choosing ``'fan_in'``\n",
            "            preserves the magnitude of the variance of the weights in the\n",
            "            forward pass. Choosing ``'fan_out'`` preserves the magnitudes in the\n",
            "            backwards pass.\n",
            "        nonlinearity: the non-linear function (`nn.functional` name),\n",
            "            recommended to use only with ``'relu'`` or ``'leaky_relu'`` (default).\n",
            "    \n",
            "    Examples:\n",
            "        >>> w = torch.empty(3, 5)\n",
            "        >>> nn.init.kaiming_normal_(w, mode='fan_out', nonlinearity='relu')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_iP70tMClSo",
        "colab_type": "text"
      },
      "source": [
        "See the \n",
        "- choosing 'fan_in' preserves the magnitude of the variance of the wights in the forward pass\n",
        "- choosing 'fan_out' preserves the magnitues in the backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwXQGif_vCDA",
        "colab_type": "code",
        "outputId": "b65b1f4b-0d7b-4f11-ea0f-511d9e104b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "w1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gft8wWdBvCDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quDCPThkvCDE",
        "colab_type": "code",
        "outputId": "93c91db3-9d00-4b63-f2a6-9ea2f22e39c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.nn.Linear(m,nh).weight.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuakYrUnQGOL",
        "colab_type": "text"
      },
      "source": [
        "**We should do fan_out(backward); cz pytorch use with transposed matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47oNSHiFvCDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.nn.Linear.forward?? #what is this? why jeremy input this?\n",
        "# help(torch.nn.Linear.forward)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drxhcWV3UI6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%script false\n",
        "torch.nn.functional.linear??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGI_xKnPvCDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%script false\n",
        "help(torch.nn.functional.linear)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HULMYxz5vCC-",
        "colab_type": "code",
        "outputId": "bae95222-3630-45fa-d83d-829a0564e9bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t.mean(),t.std() #adequate to linear layer's variate, which is Relu."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5668), tensor(0.8150))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm-8gSykvCDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.Conv2d??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-eBvmbGWrpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%script false\n",
        "torch.nn.Conv2d.conv2d_forward?? #jiwon put here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5-azfxuvCDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.modules.conv._ConvNd.reset_parameters??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoFDU_Y0A1YB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x): return x.clamp_min(0.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8mOdusevCDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# what if...? mitigate mean bias...\n",
        "\n",
        "def relu(x): return x.clamp_min(0.) - 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0229qDAuvCDS",
        "colab_type": "code",
        "outputId": "54c7ae8b-5df0-4566-8d19-be85be3b5413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# kaiming init / he init for relu\n",
        "w1 = torch.randn(m,nh)*math.sqrt(2./m )\n",
        "t1 = relu(lin(x_valid, w1, b1))\n",
        "t1.mean(),t1.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2070), tensor(0.9178))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCSOydh-c645",
        "colab_type": "text"
      },
      "source": [
        "Does it really enhance bias when we extract 0.5?? (just wanted to test jeremy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16dRq1Rme9xI",
        "colab_type": "text"
      },
      "source": [
        "WE can forward pass now!!!\n",
        "\n",
        "1.   ReLU\n",
        "2.   Linear\n",
        "3.   Init\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeUh6JJBkxJs",
        "colab_type": "text"
      },
      "source": [
        "a model just can be a function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywk-diQ0vCDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1 = torch.randn(m,nh)*math.sqrt(2./m )\n",
        "t1 = relu(lin(x_valid, w1, b1))\n",
        "t1.mean(),t1.std()\n",
        "def model(xb):\n",
        "    l1 = lin(xb, w1, b1) # one linear layer\n",
        "    l2 = relu(l1) # one relu layer\n",
        "    l3 = lin(l2, w2, b2) # one more linear layer\n",
        "    return l3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bofx3go8vCDV",
        "colab_type": "code",
        "outputId": "abc4c8d5-9bc3-4304-efe7-44206f173456",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%timeit -n 10 _=model(x_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 16.7 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbFwKib3vCDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert model(x_valid).shape==torch.Size([x_valid.shape[0],1]) #(10000, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCpWx1KXvCDX",
        "colab_type": "text"
      },
      "source": [
        "### Loss function: MSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvjkqMOuvCDY",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=6372)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9jScx7ivCDY",
        "colab_type": "code",
        "outputId": "decd4091-0f61-4a75-cd08-7dd9a2b2c436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model(x_valid).shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa7Yt6vzvCDa",
        "colab_type": "text"
      },
      "source": [
        "We need `squeeze()` to get rid of that trailing (,1), in order to use `mse`. (Of course, `mse` is not a suitable loss function for multi-class classification; we'll use a better loss function soon. We'll use `mse` for now to keep things simple.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5Mb9mXevCDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0_D80revCDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train,y_valid = y_train.float(),y_valid.float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6P96B7mvCDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4vJFDfJvCDh",
        "colab_type": "code",
        "outputId": "6d25d21d-2939-4f4b-ebd9-8d3fac148318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "preds.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_84xNN3AvCDi",
        "colab_type": "code",
        "outputId": "e75b7e88-a82c-4d54-c5f8-f52c14c37c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mse(preds, y_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(37.5563)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFRFkOsRETJD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "outputId": "ccd59268-4aac-4e52-efe9-0b1fecf26f91"
      },
      "source": [
        "#what if I don't transite data type to float?\n",
        "y_train = get_data()[1] # call data again\n",
        "mse(preds, y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ae6009bef8b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# call data again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'map' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7Jdf_NjvCDl",
        "colab_type": "text"
      },
      "source": [
        "### Gradients and backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYOLsnJyvCDl",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=6493)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3HKzogr-kk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_ping(out = 'x_train'):\n",
        "    l1 = lin(x_train, w1, b1) # one linear layer\n",
        "    l2 = relu(l1) # one relu layer\n",
        "    l3 = lin(l2, w2, b2) # one more linear layer\n",
        "    return eval(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_-y_OmnvCDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse_grad(inp, targ):  #mse_input(1000,1), mse_targ (1000,1)\n",
        "    # grad of loss with respect to output of previous layer\n",
        "    inp.g = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2iaviaj-A4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b9e34e9b-ec1e-4433-e5d1-74fdba1d49f1"
      },
      "source": [
        "# - mse gradient\n",
        "y_hat = model_ping('l3') #get value from forward model\n",
        "y_hat.g = 2. *((y_hat.squeeze(-1)-y_train).unsqueeze(-1))/y_hat.shape[0]\n",
        "y_hat.g.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZcrYljxvCDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lin_grad(inp, out, w, b):\n",
        "    # grad of matmul with respect to input\n",
        "    inp.g = out.g @ w.t()\n",
        "    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
        "    b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACIGL2IjD-kR",
        "colab_type": "code",
        "outputId": "5616aa1b-6f55-4d61-b964-69cf1bd58751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# - l3 gradient\n",
        "lin2 = model_ping('l2'); #get value from forward model\n",
        "lin2.g = y_hat.g@w2.t(); lin2.g.shape\n",
        "w2.g = (lin2.unsqueeze(-1) * y_hat.g.unsqueeze(1)).sum(0);w2.g.shape\n",
        "b2.g = y_hat.g.sum(0);b2.g.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBDu7j_qvCDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu_grad(inp, out):\n",
        "    # grad of relu with respect to input activations\n",
        "    inp.g = (inp>0).float() * out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9yv-0Y399S5",
        "colab_type": "code",
        "outputId": "4cfc8ff4-05ca-4973-d7c4-76cc51964739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# - relu gradient\n",
        "lin1=model_ping('l1') #get value from forward model\n",
        "lin1.g = (lin1>0).float() * lin2.g; lin1.g.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slXBHarhI5Rk",
        "colab_type": "code",
        "outputId": "cfd3767f-6eb0-4141-a95e-ea907e4a272c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# - l1 gradient\n",
        "x_train.g = lin1.g @ w1.t(); x_train.g.shape\n",
        "w1.g = (x_train.unsqueeze(-1) * lin1.g.unsqueeze(1)).sum(0); w1.g.shape\n",
        "b1.g = lin1.g.sum(0);b1.g.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWnG8TSSvCDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_and_backward(inp, targ):\n",
        "    # forward pass:\n",
        "    l1 = inp @ w1 + b1\n",
        "    l2 = relu(l1)\n",
        "    out = l2 @ w2 + b2\n",
        "    # we don't actually need the loss in backward!\n",
        "    loss = mse(out, targ)\n",
        "    \n",
        "    # backward pass:\n",
        "    mse_grad(out, targ)\n",
        "    lin_grad(l2, out, w2, b2)\n",
        "    relu_grad(l1, l2)\n",
        "    lin_grad(inp, l1, w1, b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR-d8wUvzjcW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b802a0d0-2feb-44d6-9b8b-1bb0b4f2c9d0"
      },
      "source": [
        "%time forward_and_backward(x_train, y_train)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.79 s, sys: 74.9 ms, total: 3.86 s\n",
            "Wall time: 1.95 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDjwnZJAvCDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save for testing against later\n",
        "w1g = w1.g.clone()\n",
        "w2g = w2.g.clone()\n",
        "b1g = b1.g.clone()\n",
        "b2g = b2.g.clone()\n",
        "ig  = x_train.g.clone()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPM0-q9rVPKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%script false\n",
        "w1g[0,]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AkGyVgovCDx",
        "colab_type": "text"
      },
      "source": [
        "- We cheat a little bit and use PyTorch autograd to check our results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2sBYxSyvCDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xt2 = x_train.clone().requires_grad_(True)\n",
        "w12 = w1.clone().requires_grad_(True)\n",
        "w22 = w2.clone().requires_grad_(True)\n",
        "b12 = b1.clone().requires_grad_(True)\n",
        "b22 = b2.clone().requires_grad_(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXRezmXavCDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(inp, targ):\n",
        "    # forward pass:\n",
        "    l1 = inp @ w12 + b12\n",
        "    l2 = relu(l1)\n",
        "    out = l2 @ w22 + b22\n",
        "    # we don't actually need the loss in backward!\n",
        "    return mse(out, targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxtbRtSLvCD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cec66e74-0cc6-4033-bc86-3994547ec3b2"
      },
      "source": [
        "%time\n",
        "loss = forward(xt2, y_train)\n",
        "loss.backward()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
            "Wall time: 4.05 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQao3tw4vCD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "48dcbdb4-3c6d-4ab6-c220-b36ae4297e09"
      },
      "source": [
        "%time\n",
        "loss = forward(x_train, y_train)\n",
        "loss.backward()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 4.53 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbfSqSz1vCD5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "c036b818-f132-4237-a2ed-f48d0a0e8cb0"
      },
      "source": [
        "test_near(w22.grad, w2g)\n",
        "test_near(b22.grad, b2g)\n",
        "test_near(w12.grad, w1g)\n",
        "test_near(b12.grad, b1g)\n",
        "test_near(xt2.grad, ig)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-b2a6e43a7926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw22\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb22\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw12\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb12\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/dlff-note/nbs/dl2/exp/nb_01.py\u001b[0m in \u001b[0;36mtest_near\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/dlff-note/nbs/dl2/exp/nb_01.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"{cname}:\\n{a}\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: near:\ntensor([[  4.4173],\n        [ -6.1946],\n        [  0.7010],\n        [  3.6692],\n        [ -0.1159],\n        [  5.3441],\n        [-19.8665],\n        [  2.0360],\n        [  4.2772],\n        [  3.5377],\n        [ -0.1557],\n        [ -3.6126],\n        [  4.0639],\n        [  4.6142],\n        [  5.3472],\n        [  8.2796],\n        [ -0.5696],\n        [  6.0189],\n        [  1.4587],\n        [ -4.1714],\n        [  3.0493],\n        [-10.6584],\n        [ -1.2395],\n        [ -0.6368],\n        [  0.4405],\n        [ -9.0118],\n        [  5.0737],\n        [  1.6570],\n        [ -0.1087],\n        [ -2.5574],\n        [  2.0502],\n        [  5.0044],\n        [  5.5607],\n        [ 10.0037],\n        [ -3.2851],\n        [ 12.3878],\n        [  6.0831],\n        [  1.2996],\n        [  5.8215],\n        [  2.7839],\n        [-11.3031],\n        [  2.3120],\n        [ -2.1160],\n        [  4.7617],\n        [ -1.8917],\n        [ -3.2495],\n        [ -2.1583],\n        [ -5.9278],\n        [ -1.8007],\n        [ -2.8228]])\ntensor([[ 2.2086],\n        [-3.0973],\n        [ 0.3505],\n        [ 1.8346],\n        [-0.0580],\n        [ 2.6721],\n        [-9.9332],\n        [ 1.0180],\n        [ 2.1386],\n        [ 1.7688],\n        [-0.0778],\n        [-1.8063],\n        [ 2.0319],\n        [ 2.3071],\n        [ 2.6736],\n        [ 4.1398],\n        [-0.2848],\n        [ 3.0095],\n        [ 0.7294],\n        [-2.0857],\n        [ 1.5246],\n        [-5.3292],\n        [-0.6197],\n        [-0.3184],\n        [ 0.2203],\n        [-4.5059],\n        [ 2.5369],\n        [ 0.8285],\n        [-0.0543],\n        [-1.2787],\n        [ 1.0251],\n        [ 2.5022],\n        [ 2.7803],\n        [ 5.0019],\n        [-1.6425],\n        [ 6.1939],\n        [ 3.0415],\n        [ 0.6498],\n        [ 2.9108],\n        [ 1.3919],\n        [-5.6516],\n        [ 1.1560],\n        [-1.0580],\n        [ 2.3808],\n        [-0.9459],\n        [-1.6247],\n        [-1.0791],\n        [-2.9639],\n        [-0.9004],\n        [-1.4114]])"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HNIwHNGvCD7",
        "colab_type": "text"
      },
      "source": [
        "## Refactor model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIrWDGruvCD8",
        "colab_type": "text"
      },
      "source": [
        "### Layers as classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXdcU1i1vCD_",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=7112)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bjA9l64vCEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu():\n",
        "    def __call__(self, inp):\n",
        "        self.inp = inp\n",
        "        self.out = inp.clamp_min(0.)-0.5\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self): self.inp.g = (self.inp>0).float() * self.out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSY7DCE6vCEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin():\n",
        "    def __init__(self, w, b): self.w,self.b = w,b\n",
        "        \n",
        "    def __call__(self, inp):\n",
        "        self.inp = inp\n",
        "        self.out = inp@self.w + self.b\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        self.inp.g = self.out.g @ self.w.t()\n",
        "        # Creating a giant outer product, just to sum it, is inefficient!\n",
        "        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
        "        self.b.g = self.out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwx7XeApvCEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mse():\n",
        "    def __call__(self, inp, targ):\n",
        "        self.inp = inp\n",
        "        self.targ = targ\n",
        "        self.out = (inp.squeeze() - targ).pow(2).mean()\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKd7lQnUvCEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "    def __init__(self, w1, b1, w2, b2):\n",
        "        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n",
        "        self.loss = Mse()\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x, targ)\n",
        "    \n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for l in reversed(self.layers): l.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRthL98vvCEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model(w1, b1, w2, b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlbU1NDrjRpM",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36RqbnykvCEO",
        "colab_type": "code",
        "outputId": "e29e40b2-2a66-4ae7-b015-7ad27959675c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%time \n",
        "loss = model(x_train, y_train)\n",
        "model.backward()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.96 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkuK7yYtvCER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w2g, w2.g)\n",
        "test_near(b2g, b2.g)\n",
        "test_near(w1g, w1.g)\n",
        "test_near(b1g, b1.g)\n",
        "test_near(ig, x_train.g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkLyRrrCrHQO",
        "colab_type": "text"
      },
      "source": [
        "##### experimenting by myself(broadcasting, einsum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKqXkcDjjXxL",
        "colab_type": "text"
      },
      "source": [
        "- outer product -> broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99bXXIH7Ta-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "91913086-fa07-4a62-99dc-5aee5efed3d6"
      },
      "source": [
        "%time tmp = x_train @ w1"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 115 ms, sys: 871 µs, total: 116 ms\n",
            "Wall time: 61.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci6A2Ep0qAg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f4fd0c91-e6da-4d86-8c78-401ef689efde"
      },
      "source": [
        "tmp.shape"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2DNK8FlfMJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "d19dff66-352f-484d-ea4f-09ef3456f56f"
      },
      "source": [
        "%time\n",
        "for i in range(len(x_train)):\n",
        "    tmp[i] = (x_train[i,:,None] * w1).sum(0)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.25 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-582c5ccb2ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tmp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XomqvD-WjciA",
        "colab_type": "text"
      },
      "source": [
        "- einsum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8_gCNQpnEuj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "22e88bb3-eec6-45e5-8d90-0a7c1494ecab"
      },
      "source": [
        "lin2.shape, y_hat.shape"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50000, 50]), torch.Size([50000, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T69ONxOjkmz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4b15adcb-39cf-4f47-c897-3a8ddac95393"
      },
      "source": [
        "%time w2.g = (lin2.unsqueeze(-1) * y_hat.g.unsqueeze(1)).sum(0)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.7 ms, sys: 174 µs, total: 10.9 ms\n",
            "Wall time: 6.92 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoJh8_FcjkzH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a0a8c948-9ae9-4d78-d945-6b08690e3f33"
      },
      "source": [
        "%time w2.g=torch.einsum(\"bi, bj\", lin2, y_hat.g)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.14 ms, sys: 35 µs, total: 2.18 ms\n",
            "Wall time: 1.77 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSJuqcj-iYoU",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP26MpJIvCEU",
        "colab_type": "text"
      },
      "source": [
        "### Module.forward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk7eJTvBs4jS",
        "colab_type": "text"
      },
      "source": [
        "- Role of `__call__` changed. No more `__call__` for **implementing** forward pass.\n",
        "- By initializing the forward with `__call__`, Module.forward() use overriding to maximize reusability. So any layer inherit Module, can use parent's function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqEBjamPvCEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Module():\n",
        "    def __call__(self, *args):\n",
        "        self.args = args\n",
        "        self.out = self.forward(*args)\n",
        "        return self.out\n",
        "    \n",
        "    def forward(self): raise Exception('not implemented')\n",
        "    def backward(self): self.bwd(self.out, *self.args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baN7cq_1vCEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu(Module):\n",
        "    def forward(self, inp): return inp.clamp_min(0.)-0.5\n",
        "    def bwd(self, out, inp): inp.g = (inp>0).float() * out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzOg0G3TvCEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin(Module):\n",
        "    def __init__(self, w, b): self.w,self.b = w,b\n",
        "        \n",
        "    def forward(self, inp): return inp@self.w + self.b\n",
        "    \n",
        "    def bwd(self, out, inp):\n",
        "        inp.g = out.g @ self.w.t()\n",
        "        self.w.g = torch.einsum(\"bi,bj->ij\", inp, out.g)\n",
        "        self.b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuvD4ILgvCEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mse(Module):\n",
        "    def forward (self, inp, targ): return (inp.squeeze() - targ).pow(2).mean()\n",
        "    def bwd(self, out, inp, targ): inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn0pSLRYvCEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "    def __init__(self):\n",
        "        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n",
        "        self.loss = Mse()\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x, targ)\n",
        "    \n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for l in reversed(self.layers): l.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kzTL0GtvCEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14_dh0u5vCEg",
        "colab_type": "code",
        "outputId": "d3fb73fd-fb5f-4f29-e342-e41e7a22f69f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%time\n",
        "loss = model(x_train, y_train)\n",
        "model.backward()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 4.29 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEMvPHTkvCEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w2g, w2.g)\n",
        "test_near(b2g, b2.g)\n",
        "test_near(w1g, w1.g)\n",
        "test_near(b1g, b1.g)\n",
        "test_near(ig, x_train.g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bngO0c4EvCEj",
        "colab_type": "text"
      },
      "source": [
        "### Without einsum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5iQVSasvCEj",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=7484)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUWJCOWzvCEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin(Module):\n",
        "    def __init__(self, w, b): self.w,self.b = w,b\n",
        "        \n",
        "    def forward(self, inp): return inp@self.w + self.b\n",
        "    \n",
        "    def bwd(self, out, inp):\n",
        "        inp.g = out.g @ self.w.t()\n",
        "        self.w.g = inp.t() @ out.g\n",
        "        self.b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvv_vkCevCEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhDRbmqnvCEn",
        "colab_type": "code",
        "outputId": "7d55567e-7610-4ee9-ced8-d103e63f788c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%time \n",
        "loss = model(x_train, y_train)\n",
        "model.backward()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
            "Wall time: 3.81 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWKmQAWOvCEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w2g, w2.g)\n",
        "test_near(b2g, b2.g)\n",
        "test_near(w1g, w1.g)\n",
        "test_near(b1g, b1.g)\n",
        "test_near(ig, x_train.g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhGSp5lSvCEs",
        "colab_type": "text"
      },
      "source": [
        "### nn.Linear and nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHKCU19ovCEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0w_NYEJvCEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "        self.loss = mse\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x.squeeze(), targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJTK3khQvCEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuC4z-Y4vCEw",
        "colab_type": "code",
        "outputId": "c7c67419-8205-49a5-c5ee-43471e44e2e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%time\n",
        "loss = model(x_train, y_train)\n",
        "loss.backward()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
            "Wall time: 5.01 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov7pCiYmvCEx",
        "colab_type": "text"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FDM9rE4vCEy",
        "colab_type": "code",
        "outputId": "8ff21a5c-5b74-4dd7-e4c5-b8ee74a02563",
        "colab": {}
      },
      "source": [
        "!./notebook2script.py 02_fully_connected.ipynb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 02_fully_connected.ipynb to nb_02.py\r\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}