{
  "welcome back to lesson three so we're",
  "going to start with a quick correction",
  "which is to let you know that when we",
  "referred to this chart is coming from",
  "Chora",
  "last week we were correct it did come",
  "from Chora but actually we realized",
  "originally it came from Andrew earns",
  "excellent machine learning course on",
  "Coursera so apologies for the incorrect",
  "citation but in exchange let's talk",
  "about Andrew owns excellent machine",
  "learning course on Coursera it's it's",
  "really great as you can see people gave",
  "it four point nine out of five stars in",
  "some ways it's a little dated but a lot",
  "of the content really is as as",
  "appropriate as ever and taught in a more",
  "bottom-up style so it can be quite nice",
  "to combine andrew's bottom-up style and",
  "our top-down style and meet somewhere in",
  "the middle also if you're interested in",
  "more machine learning foundations you",
  "should check out our machine learning",
  "course as well if you go to course too",
  "fast at AI and click on the machine",
  "learning button that will take you to",
  "our course which is about twice as long",
  "as this deep learning course and kind of",
  "takes you much more gradually through",
  "some of the foundational stuff around",
  "validation sets and model interpretation",
  "and our PI torch tensors work and and",
  "stuff like that so I think all these",
  "courses together if you want to really",
  "dig deeply into the material do all of",
  "them I know a lot of people who have and",
  "end up saying oh I got more out of each",
  "one by doing the whole lot or you can",
  "skip back within four words see which",
  "one works for you so we started talking",
  "about deploying your web app last week",
  "one thing that's going to make life a",
  "lot easier for you is that on the course",
  "v3 website there's a production section",
  "where right now we have one platform but",
  "more will be added by the time this",
  "video comes out showing you how to",
  "deploy your web app really really easily",
  "and when I say easily for example here's",
  "the how to deploy on site guide created",
  "by San Francisco study group member neph",
  "John as you can see it it's just a page",
  "there's almost nothing to do",
  "and it's free it's not going to serve",
  "10,000 simultaneous requests but it'll",
  "certainly get you started and I found it",
  "works really well it's fast and so",
  "deployment you know deploying a model",
  "doesn't have to be slow more complicated",
  "anymore",
  "and the nice thing is you can kind of",
  "use this for an MVP and if you do find",
  "just started to get a thousand",
  "simultaneous requests then you know that",
  "things are working out and you can start",
  "to you know upgrade your instance types",
  "or you know add to a more traditional",
  "you know big engineering approach so if",
  "you actually use this starter kit it",
  "will actually create my teddy bear",
  "finder for you and this is an example of",
  "my teddy bear fighter so the idea is",
  "it's like it's as simple as possible",
  "this template so you can fill in your",
  "own style sheets your own custom logic",
  "and so forth this is kind of designed to",
  "be a minimal thing so you can see",
  "exactly what's going on the back end is",
  "a simple kind of rest style you know",
  "interface it sends back JSON and the",
  "front end is a super simple little",
  "JavaScript thing so yeah it should be a",
  "good way to get a sense of how to build",
  "a web app which talks to a PI torch",
  "model so examples of web apps people",
  "have built during the week",
  "Edward Ross built the what car is that",
  "Apple more specifically the what",
  "Australian car is that is that I thought",
  "it was kind of interesting that Edward",
  "said on the forum that the building of",
  "the app was actually a great experience",
  "in terms of understanding how dumb how",
  "the model works himself better and like",
  "it's it's a it's interesting that he's",
  "describing like trying it out on his",
  "phone lot of people think like oh if I",
  "want something on my phone I have to",
  "create some kind of mobile tensorflow",
  "onn X whatever tricky mobile app you",
  "really don't you can run it all in the",
  "cloud and make it just a web app or use",
  "some kind of simple little GUI front-end",
  "that talks to a",
  "back end it's not that often that you'll",
  "need to actually run stuff on the phone",
  "so this is a good example of that",
  "see Werner has created a guitar",
  "classifier you can decide whether your",
  "food is healthy or not apparently this",
  "one is healthy that can't be right I",
  "would have thought of hamburger is more",
  "what we're looking for but there you go",
  "apparently Trinidad and Tobago is the",
  "home of the hummingbird so if you're",
  "visiting you can find out what kind of",
  "hummingbirds you're looking at you can",
  "decide whether or not to eat a mushroom",
  "if you happen to be one of the cousins",
  "of Charlie Harrington you can now figure",
  "out who is who I believe this was",
  "actually designed for his fiancee even",
  "will tell you about the interests of",
  "this particular cousin so you know",
  "fairly niche application but you know",
  "apparently there are 36 people who will",
  "appreciate this at least I have no",
  "cousins that's a lot of cousins this is",
  "an example of a a nap which actually",
  "takes a video feed and turns it into an",
  "emotion classifier that's pretty cool I",
  "like it",
  "team 26 good job here's a similar one",
  "for American Sign Language and so like",
  "it's it's not a big step from taking a",
  "single image model to taking a video",
  "model you can just grab the occasional",
  "frame put it through your model and and",
  "update the update the UI as the kind of",
  "model results come in so it's really",
  "cool that you can do this kind of stuff",
  "either in plant or in browser nowadays",
  "Henri plushie is built your city from",
  "space which he describes as creepy how",
  "accurate it is so here's why I live",
  "which it figured out was in the United",
  "States it's interesting he describes",
  "here how he actually had to be very",
  "thoughtful",
  "the validation set he built make sure",
  "that the satellite tails were not",
  "overlapping or close to each other and",
  "doing so he realized he had to download",
  "more data but once he did he got this",
  "amazingly effective model that can look",
  "at satellite imagery and figure out what",
  "country it's from I thought this one was",
  "pretty interesting which was doing",
  "univariate time series analysis by",
  "converting it into a picture using",
  "something I've never heard of a gradient",
  "angular field but he says he's getting",
  "closer to say that the results for",
  "univariate time series modeling into a",
  "picture and so I like this is I like",
  "this idea of turning stuff that's not a",
  "picture into a picture so something",
  "really interesting about this project",
  "which was looking at a motion",
  "classification from faces was that he",
  "was specifically asking the question how",
  "well does it go without changing",
  "anything just using the default settings",
  "which i think is a really interesting",
  "experiment because we were all told it's",
  "really hard to train models and it takes",
  "a lot of you know specific knowledge and",
  "actually we're finding that that's often",
  "not the case and he looked at this",
  "facial expression recognition dataset",
  "there was a 20-17 paper that he compared",
  "his results to and he got equal more",
  "slightly better results than the state",
  "of the art paper on face recognition",
  "recognition without doing any customer",
  "eye perimeter training at all so that",
  "was really cool and then Elena Harley",
  "who I featured one of her works last",
  "week has done another really cool work",
  "in the genomic space which is looking at",
  "variant analysis looking at false",
  "positives in these kinds of pictures and",
  "she found she was able to decrease the",
  "number of false positives coming out of",
  "the kind of industry standard software",
  "she was using by 500% by using a deep",
  "learning workflow I think this is a nice",
  "example of something where if you are",
  "going through you know spending hours",
  "every day looking at",
  "in this case looking at you know it's",
  "kind of get rid of the false positives",
  "maybe you can make that a lot faster by",
  "using deep learning to do a lot of the",
  "work for you and again this is an",
  "example of a computer vision based",
  "approach on something which originally",
  "wasn't actually images so that was yeah",
  "that's a really cool application so",
  "really nice to see what people have been",
  "building in terms of both web apps and",
  "just classifiers what we're going to do",
  "today is look at a whole lot more",
  "different types of model that you can",
  "build and we're going to kind of zip",
  "through them pretty quickly and then",
  "we're going to go back and say like oh",
  "how did all these things work what's the",
  "common denominator but all of these",
  "things you can create web apps from",
  "these as well but you'll have to think",
  "about how to slightly change that",
  "template to make it work with these",
  "different applications I think that'll",
  "be a really good exercise in making sure",
  "you understand the material so the first",
  "one we're going to look at is a data set",
  "of satellite images and satellite",
  "imaging is a really fertile area for",
  "deep learning it's certainly a lot of",
  "people already using deep learning and",
  "satellite imaging but only scratching",
  "the surface and the data set that we're",
  "going to look at looks like this it has",
  "satellite tiles and for each one as you",
  "can see there's a number of different",
  "labels for each tile one of the labels",
  "or way always represents the weather",
  "that's shown so in this case cloudy or",
  "partly cloudy and then all of the other",
  "labels tell you any interesting features",
  "that are seen there so primary means",
  "primary rainforest agriculture means",
  "there's some farming road road and so",
  "forth so as I'm sure you can tell this",
  "is a little different to all the",
  "classifiers we've seen so far because",
  "there's not just one label is",
  "potentially multiple labels so",
  "multi-label classification can be done",
  "in a very similar way but the first",
  "thing we're going to need to do is to",
  "download the data now this data comes",
  "from cattle cargo is",
  "known for being a competitions website",
  "and its really great to download data",
  "from Kegel when you're learning because",
  "you can see how would I have gone in",
  "that competition and it's a good way to",
  "see whether you kind of know what you're",
  "doing I tend to think the goal is to try",
  "and get in the top 10% and in my",
  "experience all the people in the top 10%",
  "of a competition really know what",
  "they're doing",
  "so if you can get in the top 10% then",
  "and that's a really good sign",
  "pretty much every Kegel data set is not",
  "available for download outside of cattle",
  "at least the competition data sets so",
  "you have to download it through cattle",
  "and the good news is that cowbell",
  "provides a python-based download at all",
  "which you can use so we've got a quick",
  "description here of how to download",
  "stuff from cattle so to install stuff to",
  "download stuff from cattle you first",
  "have to install the the cattle download",
  "tool so just pip install cattle and so",
  "you can see what we tend to do when",
  "there's one-off things to do is we show",
  "you the commented out version in the",
  "notebook and you can just remove the",
  "comment so here's a cool tip for you if",
  "you select a few lines and then hit",
  "control slash it uncomment them all and",
  "then when you're done select them again",
  "control slash again and recommence the",
  "ball okay so if you run this line it'll",
  "install cattle for you depending on your",
  "platform you may need sudo you may need",
  "slash something else slash pip you may",
  "need source activate so have a look on",
  "the setup instructions actually the",
  "returning to work instructions on the",
  "course website to see like when we do",
  "condor install you have to do the same",
  "basic steps for your pip install so once",
  "you've got that module installed you can",
  "then go ahead and download the data and",
  "basically it's as simple as saying calc",
  "or competitions download the competition",
  "name and then the files that you want",
  "the only other steps before you do that",
  "is that you have to authenticate",
  "yourself and you'll see there's a little",
  "bit of information here on",
  "exactly how you can go about downloading",
  "from Kegel the the file containing your",
  "your API authentication information so I",
  "won't bother going through it here but",
  "is follow these deaths sometimes stuff",
  "on Kegel is not just zipped or tired but",
  "it's compressed with a program called",
  "7-zip which will have a 7z extension if",
  "that's the case you'll need to either",
  "app to install P 7-zip or here's",
  "something really nice some kind person",
  "has actually created a condor",
  "installation of 7-zip that works on",
  "every platform so you can always just",
  "run this condor install doesn't even",
  "require a sudo or anything like that and",
  "this is actually a good example of where",
  "condor is super handy is that you can",
  "actually install binaries and libraries",
  "and and stuff like that and it's nicely",
  "cross-platform so that's a good if you",
  "don't have 7-zip installed that's a good",
  "way to get get it and so this is how you",
  "unzip a 7-zip file in this case it's",
  "tired and 7-zip so you can do this all",
  "in one step",
  "so 7z a is the name of the 7-zip archive",
  "a program that you would run okay so",
  "that's all basic stuff which if you're",
  "not so familiar with the command line",
  "and stuff it might take you a little bit",
  "of experimenting to get it working feel",
  "free to ask on the forum make sure you",
  "yes",
  "search the forum first to get started",
  "okay so once you've got the data",
  "downloaded and unzipped you can take a",
  "look at it so in this case so in this",
  "case because we have multiple labels for",
  "each tile we we clearly can't have a",
  "different folder for each image telling",
  "us what the label is we need some",
  "different way to label it and so the way",
  "the Cavill did it was they provided a",
  "CSV file that had each file name along",
  "with a list of all of the labels in",
  "order to just take a look at that CSV",
  "file we can read it using the pandas",
  "library if you haven't used pandas",
  "before it's kind of",
  "the standard way of dealing with tabular",
  "data in in Python pretty much always",
  "appears on the PD namespace in this case",
  "really well not really doing anything",
  "with it other than just showing you the",
  "contents of this file so we can read it",
  "we can take a look at the first few",
  "lines and there it is so we want to turn",
  "this into something we can use for",
  "modeling so the kind of object that we",
  "use for modeling is an object of the",
  "data bunch plus so we have to somehow",
  "create a data bunch out of this once we",
  "have a data bunch we'll be able to go",
  "show batch to take a look at it and then",
  "we'll be able to go create CNN with it",
  "and then we will be the start training",
  "okay so really the the trickiest step",
  "previously in deep learning has often",
  "been getting your data into a form that",
  "you can get it into a model so far we've",
  "been showing you how to do that using",
  "various um factory methods so methods",
  "where you basically say I want to create",
  "this kind of data from this kind of",
  "sauce with these kinds of options the",
  "problem is I've been that works fine",
  "sometimes when we showed you a few ways",
  "of doing it over the last couple of",
  "weeks but sometimes you want more",
  "flexibility because there's so many",
  "choices that you have to make about",
  "where do where do the files live and",
  "what's the structure they're in and how",
  "do the labels appear and how do you spit",
  "out the validation set and how do you",
  "transform it and so forth so we've got",
  "this unique API that I'm really proud of",
  "called the data block API and the data",
  "block API makes each one of those",
  "decisions a separate decision that you",
  "make there's separate methods and with",
  "their own parameters for every choice",
  "that you make around how do I create you",
  "know set up my data so for example to",
  "grab the planet data we would say we've",
  "got a list of image files that are in a",
  "folder and they're labeled based on a",
  "CSV with this name they have this",
  "separator remember I showed you back",
  "here that there's a space between them",
  "so by passing in separator it's going to",
  "create multiple labels the images are in",
  "this folder they have",
  "Suffolk's we're going to randomly split",
  "out a validation set with 20% of the",
  "data we're going to create data sets",
  "from that which were then going to",
  "transform with these transformations and",
  "then we're going to create a data bunch",
  "out of that which will then normalize",
  "using these statistics so there's all",
  "these different steps so to give you a",
  "sense of what that looks like the first",
  "thing I'm going to do is kind of go back",
  "and explain what are all of the PI torch",
  "and fast they are kind of classes that",
  "you need to know about that are going to",
  "appear in this process because you're",
  "good you're going to see them all the",
  "time in the first day I Docs and the PI",
  "torch does so the first one you need to",
  "know about is a class called a data set",
  "and the data set class is part of PI",
  "torch and this is the source code for",
  "the data set class as you can see it",
  "actually does nothing at all so the data",
  "set class in PI torch defines two things",
  "get item and when in python these",
  "special things that are underscore",
  "underscore something underscore",
  "underscore - Easter's call them dunder",
  "some things this would be done to get",
  "item dunder lin and they're basically",
  "special magical methods that do some",
  "special behavior and this particular",
  "method you can look them up in the",
  "python docs this particular method means",
  "that your object if you had an object",
  "called o can be indexed with square",
  "brackets something like that right so",
  "that would call get item with three as",
  "the index and then this one called len",
  "means that you can go Len o",
  "and it will call that method and you can",
  "see in this case they're both not",
  "implemented so that is to say although",
  "pi torch says you tell them to tell",
  "piped watch about your data you have to",
  "create a data set it doesn't really do",
  "anything to help you create the data set",
  "it just defines what the data set needs",
  "to do so in other words your data this",
  "data",
  "pure data is something where you can see",
  "what is the third item of data in my",
  "data set so that's what getitem does and",
  "how big is my data set that's what the",
  "length does so first AI has lots of data",
  "set subclasses that do that for all",
  "different kinds of stuff and so so far",
  "you've been seeing image classification",
  "data sets and so their data sets where",
  "getitem will return an image and a",
  "single label of what is that image so",
  "that's what a data set is now a data set",
  "is not enough to train a model the first",
  "thing we know we know we have to do if",
  "you think back to the gradient descent",
  "tutorial last week is we have to have a",
  "few images or a few items at a time so",
  "that our GPU can work in parallel",
  "remember we do this this thing called a",
  "mini batch so mini batches a few items",
  "that we present to the model at a time",
  "that it can train from in parallel so to",
  "create a mini batch we use another PI",
  "torch another pipe torch plus quite a",
  "data loader and so a data loader takes a",
  "data set in its constructor so it's now",
  "saying oh this is something I can get",
  "the third item and the fifth item in the",
  "ninth item and it's going to grab items",
  "at random and create a batch of whatever",
  "size you asked for and passed and pop it",
  "on the GPU and send it off to your model",
  "for you right so a data loader is",
  "something that grabs individual items",
  "combines them into a mini batch pops",
  "them on the GPU for modeling so that's",
  "quite a data loader and that comes from",
  "a data set so you can see already",
  "there's kind of choices you have to make",
  "you know what kind of data set am i",
  "creating what is the data for it where",
  "it's going to come from and then when I",
  "create my data load or what batch size",
  "do I want to use right it still isn't",
  "enough to train a model not really",
  "because we've got no way to validate the",
  "model if all we have is a training set",
  "then we have no way to know how we're",
  "doing because we need a separate set of",
  "held out data a validation set",
  "see how we're getting along so for that",
  "we use a fast a a class called a data",
  "bunch and a data bunch is something",
  "which as it says here binds together a",
  "training data loader and a valid data",
  "loader and when you look at the fast AI",
  "Docs when you see these kind of mono",
  "spaced font things they're always",
  "referring to some symbol you can look up",
  "elsewhere so in this case you can see",
  "train DL is here and there's their point",
  "knowing what an act that there's an",
  "argument with a certain name with unless",
  "you know what that argument is so you",
  "should always look after the colon to",
  "find out that is a data loader ok so",
  "when you create a data Bunch",
  "you're basically giving it a training",
  "set data loader and a validation set",
  "data loader and that's now an object",
  "that you can send off to a learner and",
  "start that loading so they're the basic",
  "pieces so coming back to here this stuff",
  "plus this line is all the stuff which",
  "create is creating the data set so it's",
  "saying read of the images come from",
  "because the data set the indexer returns",
  "two things it returns the the image and",
  "the labels assuming it's an image data",
  "set so what are the images come from",
  "where do the labels come from and then",
  "I'm going to create two separate data",
  "sets the training and the validation",
  "this is the thing that actually turns",
  "them into piped watch data sets this is",
  "the thing that transforms them okay and",
  "then this is actually going to create",
  "the the data loader and the data bunch",
  "in one in one go so let's look at some",
  "examples of this data block API because",
  "once you understand the data block API",
  "you'll never be lost for how to convert",
  "your data set into something you can",
  "start modeling with so here's some",
  "examples of using the data block API so",
  "for example if you're looking at m mist",
  "which remember is the pictures and",
  "classes of handwritten numerals you can",
  "do something like this",
  "this what kind of data set is this going",
  "to be it's going to be an it's going to",
  "come from a list of image files which",
  "are in some folder and they're labeled",
  "according to the folder name that",
  "they're in and then we're going to split",
  "it into trained and validation according",
  "to the folder that they're in trainer",
  "validation you can optionally add a test",
  "set we're going to be talking more about",
  "test sets later in the course ok we'll",
  "convert those into PI torch data sets",
  "now that that's all set up",
  "well then transform them using this set",
  "of transforms and we're going to",
  "transform into something of this size",
  "and then we're going to convert them",
  "into a data bunch so each of those",
  "stages inside these parentheses of",
  "various parameters you can pass to",
  "customize how that all works right but",
  "in the case of something like this M",
  "nest data set all the defaults pretty",
  "much work so this is all fine",
  "so here it is so you can check let's",
  "grab something so data dot trained es is",
  "the data set not the data load of the",
  "data set so I can actually index into it",
  "with a particular number so here is the",
  "zero indexed item in the training data",
  "set it's got an image and a label or you",
  "can show batch to see an example of the",
  "pictures of it and we could then start",
  "training here are the classes that are",
  "in that data set and this a little cut",
  "down sample of M nest has threes and",
  "sevens here's an example using planet",
  "this is actually again a sub little",
  "subset of planet we use for you know",
  "make it easy to try things out so in",
  "this case again it's an image file list",
  "again we grabbing it from a folder this",
  "time we're labeling it based on a CSV",
  "file we randomly splitting it by default",
  "it's 20%",
  "creating data sets transforming it using",
  "these transforms we're going to use a",
  "smaller size and then create a data",
  "bunch there it is and so don't a bunch",
  "just know how to draw themselves amongst",
  "other things so here's some more",
  "examples we're going to be seeing some",
  "seeing later today what if we look at",
  "this data set called cam vid can vid",
  "looks like this",
  "it contains pictures and every pixel in",
  "the picture is color coded right so in",
  "this case we have a list of files in a",
  "folder and we're going to label them in",
  "this case using a function and so this",
  "function is basically the thing we're",
  "going to see it later which tells it",
  "whereabouts of the color coding for each",
  "pixel it's in a different place randomly",
  "split it in some way create some",
  "datasets in some way we can tell it for",
  "a particular list of classes you know",
  "how do we know what pixel it'll value 1",
  "versus pixel value 2 is and that was",
  "something that we can basically read in",
  "like so again some transforms create a",
  "data bunch you can optionally pass in",
  "things like what batch size do you want",
  "and again it knows how to draw itself",
  "and you can start learning with that or",
  "one more example what if we wanted to",
  "create something like this it has like",
  "bars and chair and remote control and",
  "book this is called an object detection",
  "data set so again we've got a little",
  "minimal cocoa data set cocoa is kind of",
  "the most famous academic data set for",
  "object detection we can create it using",
  "the same process grab a list of files",
  "from a folder label them according to",
  "this little function randomly split them",
  "create an object detection data set",
  "create a data bunch in this case as",
  "you'll learn when we get to object",
  "detection you have to use generally",
  "small or batch sizes or your read out of",
  "memory and as you'll also learn you have",
  "to use something called a collation",
  "function and once that's all done we can",
  "again show it and here's our object",
  "detection data set so you get the idea",
  "right so here's a really convenient",
  "notebook where will you find this ah",
  "this notebook is the documentation",
  "remember how I told you that all of the",
  "documentation comes from notebooks",
  "you'll find them in your faster yo repo",
  "in Docs underscore sauce so this which",
  "you can play with an experiment with",
  "inputs and outputs and try all the",
  "different parameters you will find",
  "datablock api examples of use if you go",
  "to the documentation here it is the data",
  "plot API examples of use right so",
  "remember everything that you want to use",
  "in fast AI you can look it up in the",
  "documentation so let's search data block",
  "API go straight there and away you go",
  "and so once you find some documentation",
  "that you actually want to try playing",
  "with yourself just look up the name data",
  "block and then you can open up a",
  "notebook with the same name in the first",
  "day I repo and play with it yourself",
  "okay so that's a quick overview of this",
  "really nice data block API and there's",
  "lots of documentation for all of the",
  "different ways you can label label",
  "inputs and split data and create data",
  "sets and so forth and so that's what",
  "we're using for planet",
  "okay so we're using that API you'll see",
  "like in the documentation these these",
  "two steps we had all joined up together",
  "we can certainly do that here too but",
  "you'll learn in a moment why it is that",
  "we're actually splitting these up into",
  "two separate steps which is also fine as",
  "well so a few interesting points about",
  "this transforms so transforms by default",
  "remember you can hit shift tab to get",
  "all the information right transforms by",
  "default will flip randomly each image",
  "right but they'll actually randomly only",
  "flip them horizontally which makes sense",
  "right if you're trying to tell if",
  "something is a cat or a dog doesn't",
  "matter whether it's pointing left or",
  "right but it wouldn't expect it to be",
  "upside down on the other hand satellite",
  "imagery whether something's cloudy or",
  "hazy or whether there's a road there or",
  "not it could absolutely be flipped",
  "upside down there's no such thing as a",
  "right way up from space so flip vert",
  "which defaults to false we're going to",
  "flip over to TRO to say like what",
  "randomly you should actually do that and",
  "it doesn't just flip it vertically it",
  "actually tries also it",
  "possible 90-degree rotation so there are",
  "eight possible kind of symmetries that",
  "it tries out so there's various other",
  "things here I've found that these",
  "particular settings work pretty well for",
  "planet one that's interesting is warp",
  "perspective warping is something which",
  "very few libraries provide and those",
  "that do provide it it tends to be really",
  "slow",
  "I think fast AI is the first work first",
  "one to provide really fast perspective",
  "warping and basically the reason this is",
  "interesting is if I kind of look at you",
  "from below versus look at you from above",
  "they're kind of your shape changes right",
  "and so when you're taking a photo of a",
  "cat or a dog",
  "you know sometimes you'll be higher",
  "sometimes you'll be lower then that kind",
  "of change of shape is certainly",
  "something that you would want to include",
  "as you're creating your training batches",
  "you want to modify it a little bit each",
  "time not true for satellite images a",
  "satellite always points straight down at",
  "the planet so if you added perspective",
  "warping you would be making changes that",
  "aren't going to be there in real life so",
  "I turn that off so this is all something",
  "called data augmentation we'll be",
  "talking a lot more about it",
  "later in the course but you can start to",
  "get a feel for the kinds of things that",
  "you can do to to augment your data and",
  "in general maybe the most important one",
  "is if you're looking at astronomical",
  "data or kind of pathology you know",
  "Digital slide data or satellite data you",
  "know data where there isn't really an up",
  "or down turning on flip verticals true",
  "is generally going to make your models",
  "generalize better okay so here's the",
  "steps necessary to create our data bunch",
  "and so now to create a satellite imagery",
  "[Music]",
  "classifier multi-label classifier that's",
  "going to figure out for each satellite",
  "tile what's the weather and what else",
  "what can I see in it there's basically",
  "nothing else to learn everything else",
  "that you've already learnt is going to",
  "be exactly nearly the same here it is",
  "learn equals create see and",
  "in data architecture right and in this",
  "case when I first built built this",
  "notebook I used resin at 34 as per usual",
  "and I found this was a case I tried",
  "resin at 50 as I always like to do I",
  "found resin at 50 helped a little bit",
  "and I had some time to run it so in this",
  "case I was using resin at 15 there's one",
  "more change I make which is metrics now",
  "to remind you a metric has got nothing",
  "to do with how the model trains changing",
  "your metrics will not change your",
  "resulting model at all the only thing",
  "that we use metrics for is we print them",
  "out during training so here it's",
  "printing out accuracy and it's printing",
  "out this other metric called F better so",
  "if you're trying to figure out how to do",
  "a better job with your model changing",
  "the metrics will never be something that",
  "you need to do they're there just to",
  "show you how you're going so that's the",
  "first thing to know you can have one",
  "metric or no metrics or a list of",
  "multiple metrics to be printed out as",
  "your models training in this case I want",
  "to know two things the first thing I",
  "want to know is the accuracy and the",
  "second thing I want to know is how would",
  "I go on cattle and cattle",
  "told me that I'm gonna be judged on a",
  "particular metric called the F score so",
  "I'm not gonna bother telling you about",
  "the F score it's not really interesting",
  "enough to be worth spending your time on",
  "you can look it up but it's it's",
  "basically this when you have a",
  "classifier you're going to have some",
  "false positives you're going to have",
  "some false negatives how do you weigh up",
  "those two things to kind of create a",
  "single number there's lots of different",
  "ways of doing that and something called",
  "the F score has is basically a nice way",
  "of combining that into a single number",
  "and there are various kinds of F scores",
  "F 1 F 2 and so forth and Kaggle said in",
  "the competition rules we're going to use",
  "a metric called",
  "F 2 so we have a metric called F beta",
  "which in other words it's f with 1 or 2",
  "or whatever depending on the value",
  "better and we can have a look at its",
  "signature and you can see that it's got",
  "a threshold in the beta okay so the",
  "beater is 2 by default and cackled said",
  "that we're going to use f2 so I don't",
  "have to change that but there's one",
  "other thing that I need to set which is",
  "a threshold what does that mean well",
  "here's the thing",
  "do you remember we had a little look the",
  "other day at the source code for the",
  "accuracy metric so he put two question",
  "marks you get the source code and we",
  "found that it used this thing called AG",
  "mix and the reason for that if you",
  "remember was we we kind of had this you",
  "know input image that came in and it",
  "went through our model and at the end it",
  "came out with a table of ten numbers",
  "right this is like if we're doing M&S;",
  "digit recognition and the ten numbers",
  "were like the probability of each of the",
  "possible digits and so then we had to",
  "look through all of those and find out",
  "which one was the biggest and so that",
  "the function in num PI or PI torch or",
  "just math notation that finds the",
  "biggest in returns its index is called",
  "Arg max all right so to get the accuracy",
  "for our pet detector we use this",
  "accuracy function the called Arg max to",
  "find out behind the scenes which Plus ID",
  "pet was the one that we're looking at",
  "and then it compared that to the actual",
  "and then took the average and that was",
  "the that was the accuracy we can't do",
  "that for satellite recognition in this",
  "case because there isn't one label we're",
  "looking for",
  "there's lots so instead what we do is we",
  "look at so in this case",
  "so I don't know if you remember but a",
  "data bunch has a special attribute",
  "called C and C is going to be basically",
  "how many outputs do we want our model to",
  "create and so for any kind of classifier",
  "we want one probability for each",
  "possible class so in other words dated C",
  "for classifiers is always going to be",
  "equal to the length of data type classes",
  "right so data dot classes there they all",
  "are there's the 17 possibilities right",
  "so there they're the we're going to have",
  "one probability for each of those but",
  "then we're not just going to pick out",
  "one of those 17 we're going to pick out",
  "any of those 17 and so what we do is we",
  "compare each probability to some",
  "threshold and then we say anything",
  "that's higher than that threshold we're",
  "going to assume that the models saying",
  "it does have that feature and so we can",
  "pick that threshold I found that for",
  "this particular data set a threshold of",
  "0.2 seems to generally work pretty well",
  "this is the kind of thing you can easily",
  "just experiment to find a good threshold",
  "so I decided I want to print out the",
  "accuracy at a threshold of 0.2 so the",
  "normal accuracy function doesn't work",
  "that way it doesn't Arg max we have to",
  "use a different accuracy function called",
  "accuracy underscore Thresh and that's",
  "the one that's going to compare every",
  "probability to a threshold and return",
  "all the things higher than that",
  "threshold and compare accuracy that way",
  "and so one of the things we had passed",
  "in is Thresh now of course our metric is",
  "going to be calling our function for us",
  "so we don't get to tell it every time",
  "every time it calls back what threshold",
  "do we want so we really want to create a",
  "special version of this function that",
  "always uses an accuracy of a threshold",
  "of point two so one way to do that would",
  "be could go define something called",
  "accuracy o2 that takes some input and",
  "some target and returns accuracy",
  "threshold with that input and that",
  "target and a threshold of 0.2",
  "do it that way okay but it's so common",
  "that you want to kind of say create a",
  "new function that's just like that other",
  "function that we're always going to call",
  "it with a particular parameter that",
  "computer science has a term for that",
  "it's called a partial that's what a",
  "partial function application and so",
  "Python three has something called",
  "partial that takes some function and",
  "some lists of keywords and values and",
  "creates a new function that is exactly",
  "the same as this function that is always",
  "going to call it with that keyword",
  "argument so yeah this is exactly the",
  "same thing as a thing I just typed in a",
  "co2 is now a new function that calls",
  "accuracy Thresh with a threshold 0.2 and",
  "so this is a really common thing to do",
  "particularly with the FASTA a library",
  "because there's lots of places where you",
  "have to pass in functions and you very",
  "often want to pass in a slightly",
  "customized version of a function so that",
  "here's how you do it so here I've got an",
  "accuracy threshold point - I've got a F",
  "beta threshold point - I can pass them",
  "both in his metrics and I can then go",
  "ahead and do all the normal stuff LR",
  "find recorded up plot find the thing",
  "with the steepest slope so I don't know",
  "somewhere around money Nick - so we'll",
  "make that our learning rate and then fit",
  "for awhile with five comma slice LR and",
  "see how we go okay and so we've got an",
  "accuracy of about 96% and an F beta of",
  "about 0.9 to 6 and so you could then go",
  "and have a look at Planet leaderboard",
  "private leaderboard okay and so the top",
  "fiftieth is about 0.93 so we kind of say",
  "like oh we're on the right track okay",
  "with some something we're doing we're",
  "doing fine so as you can see like once",
  "you get to a point that the data is",
  "there it's very little extra - most of",
  "the time so when your model makes an",
  "incorrect prediction in a deployed app",
  "is there a good way to record that air",
  "and use that learning",
  "improve the model in a more targeted way",
  "oh yeah",
  "that's a great question so the first bit",
  "is there a way to record that couse",
  "there is you record it that's up to you",
  "right so maybe some of you can try it",
  "this week have you you need to have your",
  "user tell you you were wrong this",
  "Australian car you said it was a holder",
  "and actually it's a falcon so first of",
  "all you'll need to collect that feedback",
  "and the only way to do that is to ask",
  "the user to tell you when it's wrong so",
  "you an app need to record in some log",
  "somewhere something saying you know this",
  "was the file I've stored it here",
  "this was the prediction I made this was",
  "the extra life of you know this is the",
  "actual that they told me and then at the",
  "end of the day or at the end of the week",
  "you could set up a little job to run",
  "something or you can manually run",
  "something and what are you going to do",
  "you're going to do some fine-tuning",
  "what does fine-tuning look like good",
  "segue Rachel it looks like this",
  "alright so let's pretend here's your",
  "safe model right and so then we unfreeze",
  "right and then we fit a little bit more",
  "right now in this case I'm fitting with",
  "my original data set but you could",
  "create a new data bunch with just the",
  "misclassified instances and go ahead and",
  "fit right and the misclassified ones are",
  "likely to be particularly interesting so",
  "you might want to fit at a slightly",
  "higher learning rate you know to make",
  "them kind of really mean more or you",
  "might want to run them through a few",
  "more epochs but it's exactly the same",
  "thing right you just call fit with your",
  "misclassified examples and passing in",
  "the correct classification and that",
  "should really help your model quite a",
  "lot there there are various other tweaks",
  "you can do to this but that's the basic",
  "idea next question could someone talk a",
  "bit more about the data block ideology",
  "I'm not not quite sure how the blocks",
  "are meant to be used do they have to be",
  "in a certain order is there any other",
  "library that uses this type of",
  "programming that I could look at yes",
  "they do have to be in a certain order",
  "they do have to be in a certain order",
  "and it's basically the order that you",
  "see in the example of use right it's",
  "it's what kind of data do you have where",
  "does it come from how do you label it",
  "how do you split it what kind of data",
  "sets do you want optionally how do I",
  "transform it and then how do I create a",
  "data bunch from it so they're the steps",
  "I mean we invented this API I don't know",
  "if other people have independently",
  "invented it the basic idea of kind of a",
  "a pipeline of things that dot into each",
  "other is is pretty common in a number of",
  "places not so much in Python but you see",
  "it more in JavaScript although this kind",
  "of approach of like each stage produces",
  "something slightly different you don't",
  "you tend to see it more in like ETL",
  "software like extraction extraction",
  "transformation and loading software",
  "where there's kind of particular stages",
  "in a pipeline so yeah I mean it's been",
  "inspired by a bunch of things but yeah",
  "oh all you need to know is to kind of",
  "use this example to guide you and then",
  "look up the documentation to see you",
  "know which particular kind of thing you",
  "want and in this case the image file",
  "list you're actually not going to find",
  "the documentation of image file list in",
  "data blocks documentation because this",
  "is specific to the vision application so",
  "to then go and actually find out how to",
  "do something for your particular",
  "application you would then go you know",
  "to look at text and vision and so forth",
  "and that's where you can find out what",
  "are the data block API pieces available",
  "for that application and of course you",
  "can then look at the source code if",
  "you've got some totally new application",
  "you could create your own part of any of",
  "these stages like pretty much all of",
  "these functions are you know",
  "very few lines of code maybe we could",
  "look an example of one",
  "image list from folder so let's just put",
  "that somewhere temporary and then we're",
  "gonna go t dot label from CSD and you",
  "can look at the documentation to see",
  "exactly what that does and that's gonna",
  "call label from date of data frame so I",
  "mean this is already like useful like if",
  "you you know wanted to create a data",
  "frame a panda's data frame from",
  "something other than the CSV you now",
  "know that you could actually just call",
  "label from data frame you can look up to",
  "find what that does and as you can see",
  "like most fast AI functions are no more",
  "than you know a few lines of code",
  "they're normally pretty pretty",
  "straightforward to see what are all the",
  "pieces there and how can you use them",
  "it's probably one of these things that",
  "as you play around with it you'll get a",
  "good sense of how it all gets put",
  "together but if during the week there",
  "are particular things where you're",
  "thinking I don't understand how to do",
  "this please let us know and we'll try to",
  "help you sure what resources do you",
  "recommend for getting started with video",
  "for example being able to pull frames",
  "and submit them to your model",
  "I guess it's I mean the answer is it",
  "depends if you're using if you're using",
  "the web which I guess probably most of",
  "you will be then there's there's web api",
  "s-- that basically do that for you so",
  "you can grab the frames with with the",
  "web api and then they're just images",
  "which you can pass along if you're doing",
  "it client-side i guess most people tend",
  "to use OpenCV for that but maybe people",
  "during the week could who are doing",
  "these video apps can tell us what if",
  "what have you used and found useful and",
  "we can start to prepare something in the",
  "lesson wiki with a list of video",
  "resources since it sounds like some",
  "people are interested okay so just like",
  "usual we unfreeze our model and then we",
  "fit some more and we get",
  "down to nine to nine ish so one thing to",
  "notice here is that wet before we",
  "unfreeze your temp to get this shape",
  "pretty much all the time if you do your",
  "learning rate find it before you",
  "unfreeze it's pretty easy you know find",
  "the steepest slope not the bottom right",
  "remember we're trying to find the bit",
  "where we can like slide down it quickly",
  "so if you start at the bottom it's just",
  "going to send you straight off to the",
  "end here so somewhere around here and",
  "then we can call it again after you",
  "unfreeze",
  "i George only get a very different shape",
  "right and this is a little bit harder to",
  "say what to look for because it tends to",
  "be this kind of shape where you get a",
  "little bit of upward and then a kind of",
  "very gradual downward and then up here",
  "so you know I tend to kind of look for",
  "just before it shoots up and go back",
  "about 10x bad is a kind of a rule of",
  "thumb so one a neg five right and that",
  "is what I do for the first half of my",
  "slice and then for the second half of my",
  "slice I normally do whatever learning",
  "rate are used for the the frozen part so",
  "L R which was 0.01 kind of divided by 5",
  "or divided by 10 somewhere around that",
  "so that's kind of my role of thumb right",
  "look for the bit kind of at the bottom",
  "find about 10x smaller that's the number",
  "that I put here and then Li over 5 or Li",
  "over 10 is kind of what I put there",
  "seems to work most of the time we'll be",
  "talking more about exactly what's going",
  "on here is called discriminative",
  "learning rates as the course continues",
  "so how am I going to get this better",
  "than 9 to 9 because you know there are",
  "how many people in this competition",
  "about a thousand teams right so we want",
  "to get into the top 10% so the top five",
  "percent would be 0.93 one ish the top",
  "10% is going to be about nine to nine",
  "ish so we're not",
  "and so um here's a trick right I don't",
  "know if you remember but I when I",
  "created my data set I put size equals",
  "128 and actually the images that Carol",
  "gave us are 256 so I used the size of",
  "128 partially because I wanted to",
  "experiment quickly it's it's much",
  "quicker and easier to use small images",
  "to experiment but there's a second",
  "reason I now have a model that's pretty",
  "good at recognizing the contents of 128",
  "by 128 satellite images so what am I",
  "going to do if I now want to create a",
  "model that's pretty good at 256 by 256",
  "satellite images well why don't I use",
  "transfer learning why don't I start with",
  "the model that's good at 128 by 128",
  "images and fine-tune that so don't start",
  "again right and that's actually going to",
  "be really interesting because if I'm",
  "trained quite a lot if I'm on the verge",
  "of overfitting which I don't want to do",
  "right then I'm basically creating a",
  "whole new dataset effectively one where",
  "my images are twice the size on each",
  "axis right so four times bigger so it's",
  "really a totally different data set as",
  "far as my convolutional neural networks",
  "concerned so I kind of got to lose all",
  "that overfitting I get to start again so",
  "let's create a new learner right well",
  "let's let's keep our same liner but use",
  "a new data bunch where the data bunch is",
  "256 by 256 so that's why I actually",
  "stopped here right before I created my",
  "data sets because I'm going to now take",
  "this this data source and I'm going to",
  "create a new data bunch with 256 instead",
  "so let's have a look at how we do that",
  "so here it is take that source right",
  "take that source transform it with the",
  "same transforms as before but this time",
  "use size 256 now that should be better",
  "anyway because this is going to be you",
  "know higher resolution images but also",
  "I'm going to start with I haven't got",
  "rid of my learner it's the same",
  "I had before so I'm going to start with",
  "this kind of pre trade model and so I'm",
  "going to replace the data inside by",
  "learner with this new data bunch and",
  "then I will freeze again so that means",
  "I'm going back to just training the last",
  "few layers and I will do a new LR find",
  "and because I actually now have a pretty",
  "good model like it's pretty good for 128",
  "by 128 so it's probably going to be like",
  "at least okay for 256 by 256 I don't get",
  "that same sharp shape that I did before",
  "but I can certainly see where it's way",
  "too high right so I'm gonna pick",
  "something well before where it's way too",
  "high again maybe 10x smaller so here I'm",
  "gonna go 1e neg 2 over 2 that's you know",
  "seems well before it shoots up and so",
  "let's fit a little bit more okay so we",
  "frozen again so we're just training the",
  "last few layers and fit a little bit",
  "more and as you can see I very quickly",
  "remember kind of mine to weight was",
  "where we got to before after quite a few",
  "epochs we're straight up there and",
  "suddenly we've passed point 9 3 all",
  "right so we're now already kind of into",
  "the top 10% so we've hit our first goal",
  "right we're doing we're at the very",
  "least pretty competent at the problem of",
  "understeer cognizing satellite imagery",
  "but of course now we can do the same",
  "thing before we can unfreeze and train a",
  "little more ok again using the same kind",
  "of approach I described before lr over 5",
  "here and even smaller one here trained a",
  "little bit more 0.9 3 1 4 so that's",
  "actually pretty good point 9 3 1 well",
  "somewhere around top 20 ish so you can",
  "see actually when my friend Brendan and",
  "I entered this competition we came 22nd",
  "with 0.9 31 5 and we spent this was a",
  "year or two ago months trying to get",
  "here so using kind of pretty much you",
  "know defaults with",
  "tweaks and one trick which is the",
  "resizing tweak you can kind of get right",
  "up into the top of the leaderboard of",
  "this very challenging competition now I",
  "should say we we don't really know where",
  "we'd be we'd actually have to check it",
  "on the test set that Cable gave us and",
  "actually submit to the competition but",
  "you can do you can do a late submission",
  "and so later on in the course we'll",
  "learn how to do that but we certainly",
  "know we're we're doing well you know",
  "we're doing we're doing very well so",
  "that's great news and so you can see",
  "also as I kind of go along I tend to",
  "save things I just you can name your",
  "models but ever you like but I just want",
  "to basically know you know is it kind of",
  "before or after the unfreeze so I kind",
  "of had stage one or two what size were",
  "though training on what architecture was",
  "a training on so that we could have",
  "always go back and experiment pretty",
  "easily so that's that's planet",
  "multi-label classification",
  "let's look another example so another",
  "the other example next we're gonna look",
  "at is this data set called km vid and",
  "it's going to be doing something called",
  "segmentation we're going to start with a",
  "picture like this and we're going to try",
  "and create a color-coded picture like",
  "this where all of the bicycle pixels are",
  "the same color all of the road line",
  "pixels are the same color all of the",
  "tree pixels of the same color all of the",
  "building pixels are same color the sky",
  "the same color and so forth okay now",
  "we're not actually going to make them",
  "colors we're actually going to do it",
  "where each of those pixels has a unique",
  "number so in this case the top of left",
  "is building so I guess building this",
  "number for the top right is tree so tree",
  "is 26 and so forth all right so in other",
  "words this single top left pixel we're",
  "basically committing this we're going to",
  "do a classification problem just like",
  "the pet's classification for the very",
  "top left pixel we're going to say what",
  "is that top left pixel is it bicycle",
  "Road lines sidewalk",
  "what is the very top left pixel and then",
  "what is the next pixel along what is the",
  "next pixel long so we're going to do a",
  "little classification problem for every",
  "single pixel in every single image so",
  "that's called segmentation all right in",
  "order to build a segmentation model you",
  "actually need to download or create a",
  "dataset where someone has actually",
  "labeled every pixel so as you can",
  "imagine that's a lot of work okay so",
  "this is so that's going to be a lot of",
  "work you're probably not going to create",
  "your own segmentation datasets but",
  "you're probably going to download or",
  "find them from somewhere else this is",
  "very common in medicine life sciences",
  "you know if you're looking through",
  "slides at nuclei it's very likely you",
  "already have a whole bunch of segmented",
  "cells and segmented nuclei in radiology",
  "you probably already have lots of",
  "examples of segmented lesions and so",
  "forth so there's a lot of you know kind",
  "of different domain areas where there",
  "are domain-specific tools for creating",
  "these segmented images as you could",
  "guess from this example it's also very",
  "common in kind of self-driving cars and",
  "stuff like that where you need to see",
  "you know what what objects are around",
  "and where are they so in this case",
  "there's a nice data set called cambered",
  "which we can download and they have",
  "already got a whole bunch of images and",
  "segment masks prepared for us which is",
  "pretty cool and remember pretty much all",
  "of the data sets that we have provided",
  "kind of inbuilt URLs for you can see",
  "their details at coarse top faster day I",
  "slash data sets and nearly all of them",
  "are academic data sets where some very",
  "kind people have gone to all of this",
  "trouble for us",
  "so that we can use this data set and",
  "made it available for us to",
  "so if you do use it one of these",
  "datasets for any kind of project it",
  "would be very very nice if you were to",
  "go and find the citation and say you",
  "know thanks to these people for this",
  "data set okay because they've they've",
  "provided it and all they're asking in",
  "return is is for us to give them that",
  "credit okay so here is the canva data",
  "set here is the citation and on our data",
  "sets page that will link to the academic",
  "paper where it came from",
  "okay Rachel now is a good time for a",
  "question is there a way to use learn",
  "Dodd LR find and have it return a",
  "suggested number directly rather than",
  "having to plot it as a graph and then",
  "pick a learning rate by visually",
  "inspecting that graph there are a few",
  "other questions I think around more",
  "guidance on reading the learning rate",
  "finder graph yeah I mean it's a great",
  "question yeah I mean the short answer is",
  "no and the reason the answer is no is",
  "because this is still a bit more",
  "artisinal than I would like you know as",
  "you can kind of see I've been kind of",
  "saying how I read this learning rate",
  "graph depends a bit on what stage I'm at",
  "and kind of what the shape of it is I",
  "guess like the when you're just training",
  "the head",
  "so before you unfreeze it pretty much",
  "always looks like this and you can",
  "certainly create something that kind of",
  "creates a slightly you know creates a",
  "smooth version of this finds the",
  "sharpest negative slope and picked that",
  "you would probably be fine nearly all",
  "the time but then for you know these",
  "kinds of ones you know it requires a",
  "certain amount of experimentation but",
  "the good news is you can experiment",
  "right you can like you can try obviously",
  "if the lines going up you don't monitor",
  "almost certainly at the very bottom",
  "point you don't want it right because",
  "you needed to be going downwards but if",
  "you kind of start with somewhere around",
  "10x smaller than that and then also you",
  "could try another 10x more than that try",
  "a few numbers and find out which ones",
  "which ones worked best and within a",
  "small number of weeks",
  "you will find that you're picking the",
  "best learning rate most of the time all",
  "right so I don't know it's kind of so at",
  "this stage it still requires a bit of",
  "playing around to get a sense of the",
  "different kinds of shapes that you see",
  "and how to respond to them maybe by the",
  "time this video comes out someone will",
  "have a pretty reliable auto learning",
  "rate finder we're not there yet it's",
  "probably not a massively difficult job",
  "to do be an interesting project collect",
  "a whole bunch of different data sets",
  "maybe grab all the data sets from our",
  "data sets page try and come up with some",
  "simple heuristic compare it to all the",
  "different lessons I've shown but it'd be",
  "a really fun project to do but at the",
  "moment we we don't have that I'm sure",
  "it's possible that we haven't got there",
  "okay so how do we do image segmentation",
  "same way we do everything else and so",
  "basically we're going to start with some",
  "path we've just got some information in",
  "it of some sort so I always start by you",
  "know untiring my data do an LS see what",
  "I was given in this case there's a live",
  "photo record labels and the photo record",
  "images so I'll create paths for each of",
  "those we'll take a look inside each of",
  "those and you know at this point like",
  "you can see there's some kind of coded",
  "file names for the images and some kind",
  "of coded file names for the segment",
  "masks and then you kind of have to",
  "figure out how to map from one to the",
  "other you know normally these kind of",
  "data sets will come with a readme you",
  "can look at or you can look at their",
  "website often it's kind of obvious in",
  "this case I can see like these ones",
  "always have this kind of particular",
  "format these ones always have exactly",
  "the same format with an underscore PE so",
  "I kind of but I did this honestly I just",
  "guessed I thought oh it's probably the",
  "same thing underscore P and so I created",
  "a little function that basically took",
  "the file name and added the underscore P",
  "and put it in the different place",
  "and I tried opening it and it I noticed",
  "it worked so you know so I've created",
  "this little function that converts from",
  "the image file names to the equivalent",
  "label file names I opened up that to",
  "make sure it works normally we use open",
  "image to open the file and then you can",
  "go touch show to take a look at it but",
  "this as we described this is not a usual",
  "image file that contains integers so you",
  "have to use open masks rather than open",
  "image because we want to return integers",
  "not floats and fast AI knows how to deal",
  "with masks so if you go mask show it",
  "will automatically color code it for you",
  "in some appropriate way that's why we",
  "said open masks so you know we can kind",
  "of have a look inside look at the data",
  "see what the size is",
  "so there's 720 by 960 we can take a look",
  "at the data inside and so forth the",
  "other thing you might have noticed is",
  "that they gave us a file called codes",
  "text and a file called valid text so",
  "codes dot txt we can load it up and have",
  "a look inside and not surprisingly it's",
  "got a list telling us that for example",
  "number four is zero one two three four",
  "it's building top left is building there",
  "you go okay so just like we had you know",
  "Grizzlies black bears and Teddy's here",
  "we've got the coding for what each one",
  "of these pixels means so we need to",
  "create a databank so to create a data",
  "bunch we can go through the data block",
  "API and say okay we've got a list of",
  "image files that are in a folder we need",
  "to create labels which we can use with",
  "that get Y file name function we just",
  "created we then need to split into",
  "training and validation in this case I",
  "don't do it randomly why not",
  "because actually the pictures they've",
  "given us frames from videos so if I did",
  "them randomly I would be having like two",
  "frames next to each other one in the",
  "validation set one in the training set",
  "that would be far too easy that's",
  "treating right so the people that",
  "created this data set actually gave us",
  "a data set saying here is the list of",
  "file names that are meant to be in your",
  "validation set and their non contiguous",
  "parts of the video so here's how you can",
  "let your validation and training using a",
  "file name fail so from that I can create",
  "my data sets and so I actually have a",
  "list of plus names so like often with",
  "stuff like the planet data set or the",
  "pets data set we actually have a string",
  "saying you know this is a this is a pug",
  "or this is a ragdoll or this is a bur",
  "man or this is cloudy or whatever in",
  "this case you don't have every single",
  "pixel labeled with an entire string that",
  "would be incredibly inefficient they're",
  "each labeled with just a number and then",
  "there's a separate file telling you what",
  "those numbers mean so here's where we",
  "get to tell it and the data block API",
  "this is the list of what the numbers",
  "mean okay so these are the kind of",
  "parameters that the data block API gives",
  "you here's our transformations and so",
  "here's an interesting point remember I",
  "told you that for example sometimes we",
  "randomly flip an image right what if we",
  "randomly flip the independent variable",
  "image but we don't also randomly flip",
  "this one there now not matching anymore",
  "right so we need to tell fast AI that I",
  "want to transform the Y so what so X is",
  "our independent variable Y is that a",
  "pendant I want to transform the Y as",
  "well so whatever you do to the X they",
  "also want you to do to the way so",
  "there's all these little parameters that",
  "we can play with and I can create a data",
  "bunch I'm using a smaller batch size",
  "because as you can imagine because I'm",
  "creating a classifier for every pixel",
  "that's going to take a lot more GPU",
  "that's why I found a batch size of eight",
  "is all I could handle and then normalize",
  "in the usual way and this is quite nice",
  "fast AI because it knows that you've",
  "given it a segmentation problem when you",
  "call show batch it actually combines the",
  "two pieces for you and it will color",
  "code the photo isn't that nice right so",
  "you can see here the green on the trees",
  "and the red on the line",
  "and this kind of color on the walls and",
  "so forth alright so you can see here",
  "here are the pedestrians this is the",
  "pedestrians backpack so this is what the",
  "ground truth data looks like so once",
  "we've got that we can go ahead and",
  "create a learner I'll show you some more",
  "details in a moment",
  "call allow find find the sharpest bit",
  "which looks about one a neg to call fit",
  "passing in slice ela and see the",
  "accuracy and save the model and unfreeze",
  "and train a little bit more so that's",
  "the basic idea",
  "okay and so we're going to have a break",
  "and when we come back I'm going to show",
  "you some little tweaks that we can do",
  "and I'm also going to explain this",
  "custom metric that we've created and",
  "then we'll be able to go on and look at",
  "some other cool things so let's all come",
  "back at eight o'clock six minutes okay",
  "welcome back everybody and we're going",
  "to start off with a question we got",
  "during the break could you use",
  "unsupervised learning here pixel",
  "classification with the bike example to",
  "avoid needing a human to label a heap of",
  "images well not exactly",
  "unsupervised learning but you can",
  "certainly get a sense of where things",
  "are without needing these kind of labels",
  "and time permitting well we'll try and",
  "see some examples of how to do that it's",
  "you're certainly not going to get as",
  "such a quality in such a specific",
  "example as what you see here though if",
  "you want to get this level of",
  "segmentation mask you need a pretty good",
  "segmentation mask ground truth to work",
  "with",
  "and is there a reason we shouldn't",
  "deliberately make a lot of smaller data",
  "set up sets to step up from in tuning",
  "let's say 64 by 64 128 by 128 256 by 256",
  "and so on yes you should totally do that",
  "it works great try it I found this idea",
  "is something that I first came up with",
  "in the course a couple of years ago and",
  "I kind of thought it seemed obvious and",
  "just presented it as a good idea and",
  "then I later discovered that nobody had",
  "really published this before and then we",
  "started experimenting with it and it was",
  "basically the main tricks that we use to",
  "to to win the imagenet competition the",
  "dawn Banshee imagenet training",
  "competition and we're like wow people",
  "this wasn't only not not only was this",
  "not standard nobody had heard of it",
  "before there's been now a few papers",
  "that use this trick for various specific",
  "purposes but it's still largely unknown",
  "and it means that you can train much",
  "faster it generalizes better there's",
  "still a lot of unknowns about exactly",
  "like how how small and how big and how",
  "much at each level and so forth but I",
  "guess in as much as it has a name now it",
  "probably does and I guess we call it",
  "progressive resizing I found that going",
  "much under 64 by 64 tends not to help",
  "very much but yeah it's it's a it's a",
  "great technique and I definitely try a",
  "few a few different sizes what does",
  "accuracy mean for pix pixel wise",
  "segmentation is it correctly classified",
  "pixels divided by the total number of",
  "pixels yep that's it so if you mentioned",
  "each pixel was a separate you know",
  "object you're classifying it's exactly",
  "the same accuracy and so you actually",
  "can just pass the inaccuracy as",
  "geometric",
  "but in this case we actually don't we've",
  "created a new metric called accuracy cam",
  "vid and the reason for that is that when",
  "they labeled the images sometimes they",
  "labeled a pixel as void I'm not quite",
  "sure why maybe it's some that they",
  "didn't know or somebody felt it they'd",
  "made a mistake or whatever but some of",
  "the pixels avoid and in the canvas paper",
  "they say when you're reporting accuracy",
  "you should remove the void pixels so",
  "we've created a accuracy camford so all",
  "metrics take the actual output of the",
  "neural net that's the input to the actor",
  "this is what they called the inputs is",
  "the input to the metric and the target",
  "ie the labels we're trying to predict so",
  "we then basically create a mask so we",
  "look for the places where the target is",
  "not equal to Boyd and then we just take",
  "the input do the Arg max as per usual",
  "just the standard accuracy Arg max but",
  "then we just grab those that are not",
  "equal to the void code and we do the",
  "same for the target and we take the mean",
  "okay so it's it's just a standard",
  "accuracy it's almost exactly the same as",
  "the accuracy source code we saw before",
  "with the addition of this mask so this",
  "quite often happens that the particular",
  "kaggle competition metric you're using",
  "or the particular way your organization",
  "you know scores things or whatever",
  "there's often like little tweaks you",
  "have to do and this is how easy it is",
  "right and so as you'll see to do this",
  "stuff the main thing you need to know",
  "pretty well is how to do basic",
  "mathematical operations in pi torch so",
  "that's just something you kind of need",
  "to practice I've noticed that most of",
  "the examples and most of my models",
  "result in a training loss greater than",
  "the validation loss what are the best",
  "ways to correct that I should add that",
  "this still happens after trying many",
  "variations on number of",
  "and learning rate okay good question so",
  "remember from last week if you're",
  "training loss is higher than your",
  "validation loss than you're underfitting",
  "okay it definitely means that your",
  "underfitting you want your training loss",
  "to be lower than your validation loss if",
  "your underfitting",
  "you can train for longer you can train a",
  "train the last bit at a lower learning",
  "rate but if you're still under fitting",
  "then you're going to have to decrease",
  "regularization and we haven't talked",
  "about that yet so in the second half of",
  "this part of the course we're going to",
  "be talking quite a lot about",
  "regularization and specifically how to",
  "avoid overfitting or underfitting by",
  "using regularization if you want to skip",
  "ahead we're going to be learning about",
  "weight decay dropout and data",
  "augmentation will be the key things that",
  "are we talking about okay for",
  "segmentation we don't just create a",
  "convolutional neural network we can but",
  "actually a architecture called unit",
  "turns out to be better and actually the",
  "let's find it",
  "okay so this is what a unit looks like",
  "and this is from the University website",
  "where they talk about the unit and so",
  "we'll be learning about this both in",
  "this part of the course and in part two",
  "if you do it but basically this bit down",
  "on the left hand side is what a normal",
  "convolutional neural network looks like",
  "it's something which starts with a",
  "bigger big image and gradually makes it",
  "smaller and smaller and smaller and",
  "smaller until eventually you just have",
  "one prediction what a unit does is it",
  "then takes that and makes it bigger and",
  "bigger and bigger again and then it",
  "takes every stage of the downward path",
  "and kind of copies it across and it",
  "creates this new shape",
  "it's was originally actually created or",
  "published as a biomechanical image",
  "segmentation method but it turns out to",
  "be useful for far more than just",
  "biomedical image segmentation so it was",
  "presented at Mick I which is the main",
  "medical imaging conference and as of",
  "just yesterday it actually just became",
  "the most cited paper of all time from",
  "that conference so it's been incredibly",
  "useful over 3,000 citations you don't",
  "really need to know any details at this",
  "stage all you need to know is if you",
  "want to create a segmentation model you",
  "want to be saying learn add or create",
  "unit rather than create CNN but you pass",
  "at the normal stuff their data bunch and",
  "architecture and some metrics ok so",
  "having done that everything else works",
  "the same you can do the yelow finder",
  "find the slope train it for a while",
  "what's the accuracy go up save it from",
  "time to time",
  "unfreeze probably want to go about 10",
  "lists we're still going up so probably",
  "10 less than that so one enoch 5 comma",
  "lr over 5 train a bit more and there we",
  "go right now here's something",
  "interesting you can learn dot recorder",
  "is where we keep track of what's going",
  "on during training and it's got a number",
  "nice methods one of which is plot losses",
  "and this plots your training loss and",
  "your validation loss and you'll see",
  "quite often they actually go up a bit",
  "before they go down why is that that's",
  "because you can also plot your learning",
  "rate over time and you'll see that the",
  "old learning rate goes up and then it",
  "goes down why is that because we said",
  "fit one cycle and that's what fit one",
  "cycle does it actually makes the",
  "learning rate start low go up and then",
  "go down again why is that a good idea",
  "well to find out why that's a good idea",
  "let's first of all look at a really cool",
  "project done by Jose Fernandez Patil",
  "during the week he took our gradient",
  "descent demo notebook and actually",
  "plotted the weights over time not just",
  "the ground truth and model over time and",
  "he did it for a few different learning",
  "rates and so remember we had two weights",
  "we were doing basically y equals ax plus",
  "B or in his nomenclature here y equals W",
  "naught X plus W 1 and so we can actually",
  "look and see over time what happens to",
  "those weights and we know this is the",
  "correct answer",
  "Yeah right so what a learning rate of",
  "point one they're kind of like slides on",
  "in here and you can see that it takes a",
  "little bit of time to get to the right",
  "point and you can see the loss improving",
  "at a higher learning rate of 0.7 you can",
  "see that the ground truth the model",
  "jumps to the ground truth really quickly",
  "and you can see that the weights jump",
  "straight to the right place really",
  "quickly and what if we have a learning",
  "rate that's really too high you can see",
  "it takes a very very very long time to",
  "get to the right point or if it's really",
  "too high it diverges okay so you can see",
  "here why getting the right learning rate",
  "is important when you get the right",
  "learning rate it",
  "zooms into the best but very quickly now",
  "as you get closer to the final spot",
  "something interesting happens which is",
  "that you really want your learning rate",
  "to decrease right because you're kind of",
  "you're getting close to the right spot",
  "right and what actually happens so what",
  "actually happens is I can only draw 2d",
  "sorry you don't generally actually have",
  "some kind of loss function surface that",
  "looks like that and remember there's",
  "lots of dimensions but it actually tends",
  "to kind of look like bumpy like that",
  "right and so you kind of want a learning",
  "rate that's like high enough to jump",
  "over the bumps right but then once you",
  "get close to the middle you know once",
  "you get close to the the best answer you",
  "don't want to be just jumping backwards",
  "and forwards between bumps so you really",
  "want your learning rate to go down so",
  "that as you get closer you take smaller",
  "and smaller steps so that's why it is",
  "that we want our learning rate to go",
  "down at the end now this idea of",
  "decreasing the learning rate during",
  "training has been around forever and",
  "it's just called learning rate annealing",
  "but the idea of gradually increasing it",
  "at the start is much more recent and it",
  "mainly comes from a guy called Leslie",
  "Smith if you're in San Francisco next",
  "week actually you can come and join me",
  "and Leslie Smith we're having a meet-up",
  "where we'll be talking about this stuff",
  "so come along to that what Leslie",
  "discovered is that if you gradually",
  "increase your learning rate what tends",
  "to happen is that actually actually what",
  "tends to happen is that loss function",
  "surfaces tend to kind of look something",
  "like this bumpy bumpy bumpy bumpy bumpy",
  "bumpy bumpy bumpy bumpy bumpy something",
  "like this right they have flat areas",
  "and bumpy areas and if you end up in the",
  "bottom of a bumpy area that that",
  "solution will tend not to generalize",
  "very well because you've found a",
  "solution that's it's good in that one",
  "place but it's not very good",
  "in other places where else if you found",
  "one in the flat area it probably will",
  "generalize well because it's not only",
  "good in that one spot but it's good to",
  "kind of around it as well if you have a",
  "really small learning rate it'll tend to",
  "kind of plug down and stick in these",
  "places right but if you gradually",
  "increase the learning rate then it'll",
  "kind of like jump down and then as the",
  "learning rate goes up it's going to",
  "start kind of going up again like this",
  "right and then the learning rate now",
  "going to be up here it's going to be",
  "bumping backwards and forwards and",
  "eventually the learning rate starts to",
  "come down again and so it'll tend to",
  "find its way to these flat areas so it",
  "turns out that gradually increasing the",
  "learning rate is a really good way of",
  "helping the model to explore the whole",
  "function surface and try and find areas",
  "where both the loss is is low and also",
  "it's it's not bumpy because if it was",
  "bumpy it would get kicked out again and",
  "so this allows us to train at really",
  "high learning rates so it tends to mean",
  "that we solve our problem much more",
  "quickly and we tend to end up with much",
  "more generalizable solutions so if you",
  "call plot losses and find that it's just",
  "getting a little bit worse and then it",
  "gets a lot better you've found a really",
  "good maximum learning rate so when you",
  "actually call fit one cycle you're not",
  "actually passing in a learning rate",
  "you're actually passing in a maximum",
  "learning rate and if it's kind of always",
  "going down particularly after you",
  "unfreeze that suggests you could",
  "probably bump your your learning rates",
  "up a little bit because you really want",
  "to see this kind of shape it's going to",
  "train faster and generalize better just",
  "just a little bit right and return to",
  "particularly see it in the validation",
  "set the orange is the validation set",
  "right and again the difference between",
  "kind of knowing this theory and being",
  "able to do it is looking at lots of",
  "these pictures right so like after you",
  "train stuff type learn dot recorder dot",
  "and hit tab and see what's in there but",
  "and particularly the things that start",
  "with plot and start getting a sense of",
  "like what are these pictures looking",
  "like when you're getting good results",
  "and then try making the learning rate",
  "much higher try making it much lower",
  "more epochs lessee paths and get a sense",
  "for that it's not like so in this case",
  "we use the size and our transforms of",
  "the original image size over to these",
  "two slashes in Python means integer",
  "divide okay because obviously we can't",
  "have half pixel amounts in ell sizes so",
  "integer divide divided by two and we use",
  "the batch size of eight now I found that",
  "fits on my GPU it might not fit on yours",
  "if it doesn't you can just decrease the",
  "batch size down to four and this isn't",
  "really solving the problem because the",
  "problem is to segment all of the pixels",
  "not half of the pixels so I'm going to",
  "use the same trick that I did last time",
  "which is I'm now going to put the size",
  "up to the full size of the source images",
  "which means I now have to have my batch",
  "size otherwise I ran out of GPU memory",
  "and I'm then going to set my learner I",
  "can either say loan dot data equals my",
  "new data well I actually found us had a",
  "lot of trouble with kind of GPU memory",
  "so I generally restarted my kernel came",
  "back here created a new learner and",
  "loaded up the weights that I saved last",
  "time but the key thing here being that",
  "this learner now has the same weights",
  "that I had here but the data is now the",
  "full image size so I can now do an LR",
  "find again find an area where it's kind",
  "of you know well before it goes up so",
  "we're going to use one a Nick three and",
  "fit some more and then unfreeze and fit",
  "some more",
  "and you could go to loan dot show",
  "results to see how your predictions",
  "compare to the ground truth and you're",
  "gonna see they really look pretty good",
  "not bad huh",
  "so how good is pretty good an accuracy",
  "of point of ninety two point one five",
  "the best paper I know of for",
  "segmentation was a paper called the",
  "hundred layers tiramisu which developed",
  "a convolutional dense net came out about",
  "two years ago so after I trained this",
  "today I went back and looked at the",
  "paper to find their state-of-the-art",
  "accuracy here it is and I looked it up",
  "and their best was ninety one point five",
  "and we got ninety two point one so I got",
  "to say where this happened today I was",
  "like wow III don't know if better",
  "results have come out since this paper",
  "but I remember when this paper came out",
  "and it was a really big deal I was like",
  "wow this this is an exceptionally good",
  "segmentation result like when you",
  "compare it to the previous bests that",
  "they compared it to it was a big step up",
  "and so like in last year's course we",
  "spent a lot of time in the course",
  "re-implementing the hundred layers",
  "tiramisu and now with our totally",
  "default fast AI + and easily beating",
  "this and I also remember this I had to",
  "train for hours and hours and hours",
  "where else today's I trained in minutes",
  "so we've this is a super strong",
  "architecture for segmentation so yeah",
  "I'm not going to promise that this is",
  "the definite state of the art today",
  "because I haven't done a complete",
  "literature search to see what's happened",
  "in the last two years but it's certainly",
  "beating the world's best approach the",
  "last time I looked into this which was",
  "in last year's course basically and so",
  "these are kind of just all the little",
  "tricks I guess we've picked up along the",
  "way",
  "in terms of like how to train things",
  "well things like using the pre train",
  "model and things like you know using the",
  "one cycle convergence and all these",
  "little tricks they work extraordinarily",
  "well and it's really nice to be able to",
  "like show something in class where we",
  "can say you know I we actually haven't",
  "published the paper on the the exact",
  "details of how this variation of the",
  "unit works there's a few little tweaks",
  "we do but if you come back for part two",
  "we'll be going into all of the details",
  "about how we make this work so well but",
  "for you or you have to know at this",
  "stage is that you can say learner doctor",
  "yet unit and you should get great",
  "results also there's another trick you",
  "can use if you're running out of memory",
  "a lot which is you can actually do",
  "something called mixed precision",
  "training and mixed precision training",
  "means that instead of using for those of",
  "you that have done a little bit of",
  "computer science instead of using single",
  "precision floating point numbers you can",
  "do all the calculations in your model",
  "with half precision floating point",
  "numbers so 16 bits instead of 32 bits",
  "tradition I mean the very idea of this",
  "has only been around really for the last",
  "couple of years in terms of like",
  "hardware that actually does this",
  "reasonably quickly and then faster a",
  "library I think is the first and",
  "probably still the only that makes it",
  "actually easy to use this if you add",
  "through FP 16 on the end of any learner",
  "call you're actually going to get a",
  "model that trains in 16-bit precision",
  "because it's so new you'll need to have",
  "kind of the most recent CUDA drivers and",
  "all that stuff for this even to work",
  "when I tried it this morning on some of",
  "the platforms it just killed the colonel",
  "so you need to make sure you've got the",
  "most recent drivers but if you've got a",
  "really recent GPU like a 20 atti",
  "not only will it work",
  "but it'll work about twice as fast as",
  "otherwise now the reason I'm mentioning",
  "it is that it's going to use less GPU",
  "Ram so even if you don't have like a 28",
  "ETA you might find or you'll probably",
  "find that things that didn't fit into",
  "your GPU without this then do fit in",
  "with this now I actually have never seen",
  "people use 16 the mixed precision",
  "floating point for segmentation before",
  "just for a bit of a laugh I tried it and",
  "actually discovered that I got even",
  "better resolved so I only found this",
  "this morning so I don't have anything",
  "more to add here rather than quite often",
  "when you make things a little bit less",
  "precise in deep learning it generalizes",
  "a little bit better and I you know I've",
  "never seen a 92.5 accuracy on camford",
  "before so yeah this not only will this",
  "be faster you'll be able to use bigger",
  "batch sizes but you might even find like",
  "I did that you get an even better result",
  "so that's a cool little trick now you",
  "just need to make sure that every time",
  "you create a learner you're at this 2fp",
  "16 if your kernel dies it probably means",
  "you have slightly out of date CUDA",
  "drivers or maybe even an old to old",
  "graphics card I'm not sure exactly which",
  "cards support FP 16 okay so one more",
  "before we kind of rewind sorry two more",
  "the first one I'm going to show you is",
  "an interesting data set called the be.we",
  "hippos data set and gabrielle finale was",
  "kind enough to give us permission to use",
  "this in the class his team created this",
  "this cool data set here's what the data",
  "set looks like it's pictures it's",
  "actually got a few things in it we're",
  "just going to do a simplified version",
  "and one of the things they do is they",
  "have a dot saying this is the center of",
  "the face and so we're going to try and",
  "create a model that can find this",
  "ever faced so um for this data set",
  "there's a few data set specific things",
  "we have to do which I don't really even",
  "understand but I just know from the",
  "readme that you have to they use some",
  "kind of depth sensing camera I think",
  "they actually use to connect you know",
  "Xbox Kinect there's some kind of",
  "calibration numbers that they provide in",
  "a little file which I had to read in and",
  "then they provided a little function",
  "that you have to use to take their",
  "coordinates to change it from this this",
  "depth sensor calibration thing to end up",
  "with actual coordinates so when you when",
  "you open this and you see these at all",
  "conversion routines that's just you know",
  "I'm just doing what they told us to do",
  "basically it's about nothing",
  "particularly to do with deep learning to",
  "end up with this dot the interesting bit",
  "really is where we create something",
  "which is not an image or an image",
  "segment put an image points and we'll",
  "mainly learn about this later in the",
  "course but basically image points use",
  "this idea of kind of their coordinates",
  "right they're not pixel values they're",
  "XY coordinates there's just two numbers",
  "as you can see let me see",
  "so here's an example for a particular",
  "image file name this particular image",
  "file and here it is the coordinates of",
  "the centre of the face are at 263 , 428",
  "and here it is so there's just two",
  "numbers which represent whereabouts on",
  "this picture as the centre of the face",
  "so if we're going to create a model that",
  "can find the center of a face we need a",
  "neural network that spits out two",
  "numbers but note this is not a",
  "classification model these are not two",
  "numbers that you look up in a list to",
  "find out that they're Road or building",
  "or ragdoll cat or whatever their actual",
  "locations so so far everything we've",
  "done has been a classification model",
  "something that's created labels or",
  "classes this for the first time is what",
  "we call a regression model a lot of",
  "people think regression means linear",
  "regression it doesn't regression just",
  "means any kind of model where your",
  "output is some continuous number or set",
  "of numbers so this is we need to create",
  "an image regression model something that",
  "can predict these two numbers so how do",
  "you do that same way as always right so",
  "we can actually just say I've got a list",
  "of image files it's in a folder and I",
  "want to label them using this function",
  "that we wrote that basically does the",
  "stuff that the readme says to grab the",
  "coordinates out of their text files so",
  "that's going to give me the two numbers",
  "for everyone and then I'm going to split",
  "it according to some function and so in",
  "this case that the files they gave us",
  "again they're from videos and so I",
  "picked just one folder to be my",
  "validation set in other words a",
  "different person so again I was trying",
  "to think about like how do I validate",
  "this fairly so I said well the the fair",
  "validation would be to make sure that it",
  "works well on a person that it's never",
  "seen before",
  "so my validation set is all going to be",
  "a particular person create a data set",
  "and so this data set I just tell it what",
  "kind of data set is it well they're",
  "going to be a set of point",
  "two points means you know specific",
  "coordinates do some transforms again I",
  "have to say transform y equals true",
  "because that red dot needs to move if I",
  "flip or rotate or warp okay pick some",
  "size I just picked a size that's going",
  "to work pretty quickly create a data",
  "bunch normalize it and again show batch",
  "there it is okay I noticed that there",
  "are red dots don't always seem to be",
  "quite in the middle of the face I don't",
  "know exactly what they're kind of",
  "internal algorithm for putting dots on",
  "they kind of sometimes looks like it's",
  "meant to be the nose but sometimes it's",
  "not quite the nose anyway you get the",
  "reps it's somewhere around the center of",
  "the face or the nose so how do we create",
  "a model we create a CNN but we're going",
  "to be learning a lot about loss",
  "functions in the next few lessons but",
  "generally that basically the loss",
  "function is that that that number that",
  "says how good is the model and so for",
  "classification we use this loss function",
  "called cross-entropy loss which says",
  "basically remember this from earlier",
  "lessons did you predict the correct",
  "class and were you confident of that",
  "prediction now we can't use that for",
  "regression so instead we use something",
  "called mean squared error and if you",
  "remember from last lesson we actually",
  "implemented being squared error from",
  "scratch it's just the difference between",
  "the two squared and added up together",
  "okay so we need to tell it this is not",
  "classification so we use mean squared",
  "error shown all these so this is not",
  "classification so we have to use mean",
  "squared error and then once we've",
  "created the learner we've taught it what",
  "loss function to use we can go ahead and",
  "do Ella find we can then fit and you can",
  "see here within a minute and a half",
  "our mean squared error is 0.0004 now the",
  "nice thing is about like mean squared",
  "error that's very easy to interpret",
  "right so we're trying to predict",
  "something which is somewhere around",
  "a few hundred and we're getting a",
  "squared error on average of 0.0004 so we",
  "can feel pretty confident that this is a",
  "really good model and then we can look",
  "at the results by learner results and we",
  "can see predictions ground truth it's",
  "doing nearly perfect job okay so that's",
  "how you can do image regression models",
  "so anytime you've got something you're",
  "trying to predict which is some",
  "continuous value you use an approach",
  "that's something like this so last",
  "example before we look at some kind of",
  "more foundational theory stuff NLP and",
  "next week we're going to be looking at a",
  "lot more NLP but let's now do the same",
  "thing but rather than creating a",
  "classification of pictures let's try and",
  "classify documents and so we're going to",
  "go through this in a lot more detail",
  "next week but let's do the quick version",
  "rather than importing from faster I",
  "Division are now import for the first",
  "time from faster I dot text that's where",
  "you'll find all the application specific",
  "stuff for analyzing text documents and",
  "in this case we're going to use a data",
  "set called IMDB and IMDB has lots of",
  "movie reviews they're generally about a",
  "couple of thousand words and each movie",
  "review has been classified as either",
  "negative or positive so it's just in a",
  "CSV file so we can use pandas to read it",
  "we can take a little look we can take a",
  "look at a review and basically as per",
  "usual we can either use factory methods",
  "or the data block API to create a",
  "databank so here's the quick way to",
  "create a data bunch from a CSV of texts",
  "data bunch from CSV and that's that and",
  "yeah at this point I could create a",
  "learner and start training it but we're",
  "going to show you a little bit more",
  "detail which remain going to look at",
  "next week the steps that actually happen",
  "when you create these data buns",
  "there's a few steps the first is it does",
  "something called tokenization or does it",
  "takes those words and it converts them",
  "into a standard form of tokens where",
  "there's basically each token represents",
  "a word but it does things like see here",
  "see how didn't has been turned here into",
  "two separate words and you see how",
  "everything's been lowercased see how",
  "your has been turned into two separate",
  "words so tokenization is trying to make",
  "sure that each each token each each",
  "thing that we've got with spaces around",
  "it here represents a single you know",
  "linguistic concept okay",
  "also it finds words that are really rare",
  "like really rare names and stuff like",
  "that and replaces them with a special",
  "token called unknown so anything's",
  "starting with XX in fast AI is some",
  "special token so this is tokenization so",
  "we end up with something where we've got",
  "a list of tokenized words you'll also",
  "see that things like punctuation end up",
  "with spaces around them to make sure",
  "that they're separate tokens the next",
  "thing we do is we take a complete unique",
  "list of all of the possible tokens",
  "that's called the vocab and that gets",
  "created for us and so here's the first",
  "ten items of the vocab so here is every",
  "possible token the first ten of them",
  "that appear in our all of the movie",
  "reviews and we then replace every movie",
  "review with a list of numbers and the",
  "list of numbers simply says what",
  "numbered thing in the vocab is in this",
  "place so here 6 is 0 1 2 3 4 5 6 so this",
  "is the word ah and this is 3 0 1 2 3",
  "this was a comma and so forth right so",
  "through",
  "organization and numerical ization this",
  "is the standard way in NLP of turning a",
  "document into a list of numbers we can",
  "do that with the data block API right so",
  "this time it's not image files list",
  "it's text spit data from a CSB convert",
  "them to datasets tokenize the numerical",
  "eyes them create a data bunch and at",
  "that point we can start to create a",
  "model as we learn about next week when",
  "we do NLP classification we actually",
  "create two models the first model is",
  "something called a language model which",
  "as you can see we train in a kind of a",
  "usual way we say we want to create a",
  "language model learner we train it we",
  "can save it and we unfreeze we train",
  "some more and then after we've created a",
  "language model we fine-tune it to create",
  "the classifier so here's the thing where",
  "we create the data bunch of the",
  "classifier we created learner train it",
  "and we end up with some accuracy so",
  "that's the really quick version we're",
  "going to go through it in more detail",
  "next week but you can see the basic idea",
  "of training and NLP classifier is very",
  "very very similar to creating every",
  "other model we've seen so far and this",
  "accuracy so the current state of the art",
  "for IMDB classification is actually the",
  "algorithm that we built and published",
  "with colleague called as named Sebastian",
  "Reuter and this basically what I just",
  "showed you is pretty much the state of",
  "the art algorithm with some minor tweaks",
  "you can get this up to about 95% I'm if",
  "you try really hard so this is very",
  "close to the state of the art accuracy",
  "that we developed the question okay",
  "that's a great time for question for a",
  "dataset very different than imagenet",
  "like the satellite images or genomic",
  "images shown in lesson two we should use",
  "our own stats Jeremy once said if you're",
  "using a pre trained model you need to",
  "use the same stats it was trained with",
  "why is that isn't it that normalized",
  "data with its own stats will have",
  "roughly the same distribution",
  "like imagenet the only thing I can think",
  "of which may differ is skewness is it",
  "the possibility of skewness or something",
  "else the reason of your statement and",
  "does that mean you don't recommend using",
  "pre train models with very different",
  "data sets like the one point mutation",
  "that you mentioned in lesson two nope",
  "as you can see I've used pre trade",
  "models for all of those things",
  "every time I've used an image Nate train",
  "pre train model and every time I've used",
  "image net stats why is that because that",
  "model was trained with those stats so",
  "for example imagine you're trying to",
  "classify different types of green frogs",
  "so if you were to use your own per",
  "channel means from your data set you",
  "would end up converting them to a mean",
  "of zero a standard deviation of one for",
  "each of your red green and blue channels",
  "which means they don't look like green",
  "frogs anymore they now look like grey",
  "frogs right that imagenet expects frogs",
  "to be green okay so you need to",
  "normalize with the same stats that the",
  "imagenet training people normalized with",
  "otherwise the unique characteristics of",
  "your data set won't appear anymore",
  "you've actually normalized them out in",
  "terms of the per channel statistics so",
  "you should always use the same stats",
  "that the model was trained with okay so",
  "in every case what we're doing here is",
  "we're using gradient descent with mini",
  "batches so stochastic gradient descent",
  "to fit some parameters of a model and",
  "those parameters are parameters to",
  "basically make fixed multiplications and",
  "the second half of this part we're",
  "actually going to learn about a little",
  "tweak called convolutions but it's a",
  "basically a type of matrix",
  "multiplication",
  "the thing is though no amount of matrix",
  "multiplications is possibly going to",
  "create something that can read IMDB",
  "movie reviews and decide if it's",
  "positive or negative or look at",
  "satellite imagery and decide whether",
  "it's got a road in it that's far more",
  "and linear classifier can do now we know",
  "these are deep neural networks and deep",
  "neural networks period contain lots of",
  "these matrix multiplications but every",
  "matrix multiplication is just a linear",
  "model and a lot a linear function on top",
  "of a linear function is just another",
  "linear function if you remember back to",
  "your you know high school math you might",
  "remember that if you you know have a y",
  "equals ax plus B and then you stick",
  "another you know C y plus D on top of",
  "that it's still just another slope and",
  "another intercept so no amount of",
  "stacking matrix multiplications is going",
  "to help in the slightest so what are",
  "these models actually what are we",
  "actually doing and here's the",
  "interesting thing",
  "all we're actually doing is we literally",
  "do have a matrix multiplication or a",
  "slight variation like a convolution that",
  "we'll learn about and but after each one",
  "we do something called a non linearity",
  "or an activation function an activation",
  "function is something that takes the",
  "result of that matrix multiplication and",
  "sticks it through some function and",
  "these are some of the functions that we",
  "use in the old days the most common",
  "function that we used to use was",
  "basically this shape these shapes are",
  "called sigmoid and they have you know",
  "particular mathematical definitions",
  "nowadays we almost never use those for",
  "these between H matrix multiply nowadays",
  "we nearly always use this one it's",
  "called a rectified linear unit it's very",
  "important when you're doing deep",
  "learning to use big long words that",
  "sound impressive otherwise normal people",
  "might think they can do it too but just",
  "between you and me a rectified linear",
  "unit",
  "is to find using the following function",
  "that's it",
  "okay so and if you want to be really",
  "exclusive of course you then shorten the",
  "long version and you call it a RAL you",
  "to show that you're really in the",
  "exclusive in the exclusive team so this",
  "is a value activation right so here's",
  "the crazy thing if you take your red",
  "green blue pixel inputs and you chuck",
  "them through a matrix modification and",
  "then you replace the negatives with zero",
  "and you put it through another matrix",
  "modification place the negatives at zero",
  "and you keep doing that again and again",
  "and again you have a deep learning",
  "neural network that's it right so how",
  "the hell does that work so extremely",
  "cool guy called Michael Nielsen showed",
  "how this works he has a very nice",
  "website affecting more than a website",
  "it's a book neural networks and deep",
  "learning calm and he has these beautiful",
  "little JavaScript things where you can",
  "get to play around because this was back",
  "in the old days this was back when we",
  "used to use sigmoids right and what he",
  "shows is that if you have enough little",
  "these shows these little matrix",
  "multiplications if you have enough",
  "little matrix multiplications followed",
  "by sigmoids and there's exactly the same",
  "thing works for a matrix multiplication",
  "followed by a value you can actually",
  "create arbitrary shapes right and so",
  "this this this idea that these",
  "combinations of of linear functions and",
  "nonlinearities can create arbitrary",
  "shapes actually has a name and this name",
  "is the universal approximation theorem",
  "and what it says is that if you have",
  "stacks of linear functions and",
  "nonlinearities the thing you end up with",
  "can approximate any function arbitrarily",
  "closely so you just need to make sure",
  "that you have a big enough matrix to",
  "multiply by or enough of them so if you",
  "have",
  "you know now this this this dysfunction",
  "which is just a sequence of matrix",
  "multiplies and nonlinearities where the",
  "nonlinearities can be you know basically",
  "any of these things we normally use this",
  "one if that can approximate anything",
  "then all you need is some way to find",
  "the particular values of the of the",
  "weight matrices in your matrix model",
  "players that solve the problem you want",
  "to solve and we already know how to find",
  "the values of parameters we can use",
  "gradient descent and so that's actually",
  "it right and this is the bit I find the",
  "hardest thing normally to explain to",
  "students is that we're actually done",
  "male people often come up to me after",
  "this lesson and they say what's the rest",
  "please explain to me the rest of deep",
  "learning but like no there's no rest",
  "like we have a function where we take",
  "our input pixels or whatever we multiply",
  "them by some weight matrix we replace",
  "the negatives with zeros we multiply it",
  "by another weight matrix replace the",
  "negative zeros we do that a few times we",
  "see how close it is to our target and",
  "then we use gradient descent to update",
  "our weight matrices using the",
  "derivatives and we do that a few times",
  "and eventually we end up with something",
  "that can classify movie reviews or can",
  "recognize pictures of reptile cats that",
  "that's actually it okay so it's it's the",
  "reason it's hard to understand",
  "intuitively is because we're talking",
  "about weight matrices that have you know",
  "once you read them all up something like",
  "a hundred million parameters they're",
  "very big weight matrices all right so",
  "your intuition about what multiplying",
  "something by a linear model and",
  "replacing the negative zeros a bunch of",
  "times can do your intuition doesn't hold",
  "right you just have to accept",
  "empirically the truth is doing that",
  "works really well so in part two of the",
  "course we're actually going to build",
  "these from scratch right but I mean just",
  "to skip ahead you know basically we'll",
  "find that you know it's going to be",
  "kind of five lines of code right it's",
  "going to be a little for loop that goes",
  "you know T equals you know X at weight",
  "matrix one t2 equals max of T comma zero",
  "stick that in a for loop that goes",
  "through which weight matrix and at the",
  "end calculate my loss function and of",
  "course we're not going to calculate the",
  "gradients ourselves because pi torch",
  "does that for us and that's about it so",
  "okay Kristin there's a question about",
  "tokenization I'm curious about how",
  "tokenizing words works when they depend",
  "on each other such as San Francisco yeah",
  "okay okay tokenization how do you",
  "tokenize something like san francisco",
  "san francisco contains two tokens San",
  "Francisco that's it that's how you",
  "tokenize San Francisco the Christian may",
  "be coming from people who have done like",
  "traditional NLP often need to kind of",
  "use these things called engrams and",
  "engrams are kind of this idea of like a",
  "lot of NLP in the old days was all built",
  "on top of linear models where you",
  "basically counted how many times",
  "particular strings of text appeared like",
  "the phrase San Francisco that would be a",
  "bigram",
  "for an Engram with an N of 2 the cool",
  "thing is that we're deep learning we",
  "don't have to worry about that like like",
  "with many things a lot of the complex",
  "feature engineering disappears when you",
  "do deep learning so with deep learning",
  "each token is literally just a word or",
  "in the case that the word really",
  "consists of two words like you're you",
  "split it into two words and then what",
  "we're going to do is we're going to then",
  "let the deep learning model figure out",
  "how best to combine words together",
  "now when we see like let the beep",
  "learning model figure it out of course",
  "all we really mean is find the weight",
  "matrices using gradient descent that",
  "gives the right answer like there's not",
  "really much more to it than that again",
  "there's some minor tweaks right in the",
  "second half of the course we're going to",
  "be learning about the particular tweak",
  "for image models which is using a",
  "convolution there'll be a CNN for",
  "language there's a particular tweak we",
  "do called using recurrent models or an",
  "RNN but they're very minor tweaks on on",
  "what we've just described so basically",
  "it turns out with an R and n that it it",
  "can learn that sound plus Francisco has",
  "a different meaning when those two",
  "things are together some satellite",
  "images have four channels how can we",
  "deal with data that has four channels or",
  "two channels when using pre-trained",
  "bottles yeah that's a good question I",
  "think that's something that we're going",
  "to try and incorporate into fast AI so",
  "hopefully by the time you watch this",
  "video they'll be easier ways to do this",
  "but the basic idea is a pre trained",
  "imagenet model expects a red green and",
  "blue pixels so if you've only got two",
  "channels there's a few things you can do",
  "but basically you'll want to create a",
  "third Channel and so you can create the",
  "third channel as either being all zeros",
  "or it could be the average of the other",
  "two channels and so you can just use you",
  "know normal hi torch arithmetic to",
  "create that third channel you could",
  "either do that ahead of time in a little",
  "loop and save your three Channel",
  "versions or you could create a custom",
  "data set class that does that on demand",
  "for a full channel you probably don't",
  "want to get rid of the fourth channel so",
  "instead what you'd have to do is to",
  "actually modify the model itself so to",
  "know how to do that we'll only know how",
  "to do",
  "in a couple more lessons time but",
  "basically the idea is that the initial",
  "weight matrix weight matrix is really",
  "the wrong term they're not waiting",
  "matrices their weight tensors so they",
  "can have more than just two dimensions",
  "so that weight that initial weight",
  "matrix in the neural net it's going to",
  "have it's actually a tensor and one of",
  "its axes is going to have three whatever",
  "three slices so you would just have to",
  "change that to add an extra slice which",
  "I would generally just initialize to",
  "zero or to some random numbers so that's",
  "the short version but really to answer",
  "this to understand exactly what I meant",
  "by that we're going to need a couple",
  "more lessons to get there okay",
  "so wrapping up what if we looked at",
  "today basically we started out by saying",
  "hey it's really easy now to create web",
  "apps we've got starter kits for you that",
  "show you how to create web apps and",
  "people have created some really cool web",
  "apps using what we've learned so far",
  "which is single label classification but",
  "the cool thing is the exact same steps",
  "we use to do single label classification",
  "you can also do to do multi-label",
  "classification such as in the planet or",
  "you could use to do segmentation or you",
  "could use to do or you could use to do",
  "any kind of image regression or this is",
  "probably a bit earlier if you try this",
  "yet you could do for an LP",
  "classification and a lot more so and in",
  "each case all we're actually doing is",
  "we're doing gradient descent on not just",
  "two",
  "parameters but on maybe 100 million",
  "parameters but still just plain gradient",
  "descent along with a non-linearity which",
  "is normally this one which it turns out",
  "the universal approximation theorem",
  "tells us lets us arbitrarily accurately",
  "approximate any given function including",
  "functions such as converting a spoken--",
  "waveform into the thing the person was",
  "saying while converting a sentence in",
  "Japanese to a sentence in English while",
  "converting a picture of a dog into the",
  "word dog these are all mathematical",
  "functions that we can learn using this",
  "approach so this week see if you can",
  "come up with an interesting idea of a",
  "problem that you would like to solve",
  "which is either multi-label",
  "classification or image regression or",
  "image segmentation something like that",
  "and see if you can try to solve that",
  "problem you will probably find the",
  "hardest part of solving that problem is",
  "coming up creating the data Bunch and so",
  "then you'll need to dig into the data",
  "block API to try to figure out how to",
  "create the data Bunch from the data you",
  "have and with some practice you will",
  "start to get pretty good at that it's",
  "not a huge API there's a small number of",
  "pieces it's also very easy to add your",
  "own but for now you know ask on the",
  "forum if you try something and you get",
  "stuck ok great so um next week we're",
  "going to come back and we're going to",
  "look at some more NLP we're going to",
  "learn some more about some details about",
  "how we actually train with SGD quickly",
  "we're going to learn about things like",
  "Adam and rmsprop and so forth and",
  "hopefully we're also going to show off",
  "lots of really cool web apps and models",
  "that you've all built during the week so",
  "124:49": "I'll see you then Thanks"
}